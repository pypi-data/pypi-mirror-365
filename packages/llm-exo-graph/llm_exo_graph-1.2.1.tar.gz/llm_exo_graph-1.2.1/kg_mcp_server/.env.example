# KG Engine MCP Server Configuration
# Copy this file to .env and fill in your actual values

# Neo4j Database Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-secure-password
NEO4J_DATABASE=neo4j

# LLM Configuration
# Provider: openai, ollama, litellm (auto-detected if not set)
LLM_PROVIDER=openai

# OpenAI Configuration (production recommended)
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_ORGANIZATION=your_org_id_here

# Ollama Configuration (local/development)
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama3.2:3b
# OLLAMA_BASE_URL=http://localhost:11434/v1
# Legacy compatibility:
# LLM_BASE_URL=http://localhost:11434/v1

# LiteLLM Configuration (custom endpoints with bearer tokens)
# LLM_PROVIDER=litellm
# LITELLM_BEARER_TOKEN=your-bearer-token
# LITELLM_BASE_URL=https://your-custom-endpoint.com/v1
# LITELLM_MODEL=gpt-4o
# LITELLM_ADDITIONAL_HEADERS={"X-Custom-Header": "value"}

# Performance Settings
KG_CACHE_TTL=300
KG_MAX_BATCH_SIZE=50

# Optional Settings
LOG_LEVEL=INFO

# Note: For cloud Neo4j (Neo4j AuraDB), use:
# NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
# NEO4J_PASSWORD=your-aura-password