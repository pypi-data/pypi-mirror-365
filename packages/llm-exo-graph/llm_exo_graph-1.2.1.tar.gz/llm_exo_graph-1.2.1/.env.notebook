# KG Engine Configuration for Notebook Environment

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j

# LLM Configuration
# Provider: openai, ollama, litellm (auto-detected if not set)
#LLM_PROVIDER=ollama
LLM_PROVIDER=litellm
LITELLM_MODEL=gpt-4o
LITELLM_BASE_URL=https://litellm.chatcyber.ai
LITELLM_BEARER_TOKEN=sk-DWpARzkiq2rHxz7bCdaq-w

# OpenAI Configuration (default provider)
#OPENAI_API_KEY=your_openai_api_key_here
#OPENAI_MODEL=gpt-4o
#OPENAI_BASE_URL=https://api.openai.com/v1
#OPENAI_ORGANIZATION=your_org_id

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=phi3:3.8b

# LiteLLM Configuration (for custom endpoints with bearer tokens)
#LITELLM_BEARER_TOKEN=your_bearer_token_here
#LITELLM_BASE_URL=https://your-custom-endpoint.com/v1
#LITELLM_MODEL=gpt-4o
#LITELLM_ADDITIONAL_HEADERS={"X-Custom-Header": "value"}

# Recommended models for notebooks (in order of preference):
# 1. phi3:mini (2.3GB) - Best balance of performance and size
# 2. llama3.2:1b (1.3GB) - Smallest, good for basic tasks
# 3. qwen2.5:1.5b (1.5GB) - Good JSON parsing capabilities
# 4. gemma2:2b (1.6GB) - Google model, reliable

# Performance Settings
KG_CACHE_TTL=300
KG_MAX_BATCH_SIZE=50

# Development Settings
PYTHONPATH=./src
PYTHONUNBUFFERED=1

# Optional: Logging Level
LOG_LEVEL=INFO