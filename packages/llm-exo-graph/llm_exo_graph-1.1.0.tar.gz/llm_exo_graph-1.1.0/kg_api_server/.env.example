# KG Engine API Server Configuration
# Copy this file to .env and fill in your actual values

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8080

# Neo4j Database Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j

# LLM Configuration
# Provider: openai, ollama, litellm (auto-detected if not set)
LLM_PROVIDER=openai

# OpenAI Configuration (production recommended)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_ORGANIZATION=your_org_id_here

# Ollama Configuration (local/development)
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama3.2:3b
# OLLAMA_BASE_URL=http://localhost:11434/v1
# Legacy compatibility:
# LLM_BASE_URL=http://localhost:11434/v1

# LiteLLM Configuration (custom endpoints with bearer tokens)
# LLM_PROVIDER=litellm
# LITELLM_BEARER_TOKEN=your_bearer_token_here
# LITELLM_BASE_URL=https://your-custom-endpoint.com/v1
# LITELLM_MODEL=gpt-4o
# LITELLM_ADDITIONAL_HEADERS={"X-Custom-Header": "value"}

# Performance Settings
KG_CACHE_TTL=300
KG_MAX_BATCH_SIZE=50

# Logging Configuration
LOG_LEVEL=INFO

# Security (for production)
# SECRET_KEY=your_secret_key_here
# ALLOWED_ORIGINS=http://localhost:3000,https://your-frontend.com