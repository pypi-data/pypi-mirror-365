# LLM Provider Configuration
{% if llm_provider == "openai" %}
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-3.5-turbo
{% if "retrieval" in chain_types %}
EMBEDDING_MODEL=text-embedding-ada-002
{% endif %}
{% elif llm_provider == "anthropic" %}
ANTHROPIC_API_KEY=your_anthropic_api_key_here
LLM_MODEL=claude-3-haiku-20240307
{% elif llm_provider == "ollama" %}
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama2
{% if "retrieval" in chain_types %}
EMBEDDING_MODEL=nomic-embed-text
{% endif %}
{% endif %}

# Chain Configuration
TEMPERATURE=0.7
MAX_TOKENS=1000

{% if "retrieval" in chain_types %}
# Retrieval Settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
SIMILARITY_TOP_K=5
{% endif %}

{% if include_tools %}
# Tool Configuration
SERPER_API_KEY=your_serper_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
{% endif %}

# UI Settings
{% if ui_framework == "streamlit" %}
STREAMLIT_PORT=8501
{% elif ui_framework == "fastapi" %}
FASTAPI_PORT=8000
FASTAPI_HOST=0.0.0.0
{% endif %}

# Logging
LOG_LEVEL=INFO
