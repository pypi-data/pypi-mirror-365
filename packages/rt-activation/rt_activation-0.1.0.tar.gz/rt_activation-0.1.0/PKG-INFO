Metadata-Version: 2.4
Name: rt-activation
Version: 0.1.0
Summary: Rectified Tanh Activation (RTA) function for Keras/TensorFlow
Author-email: Gaurav Pandey <gaurav.pandey1812@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/gkp1812/rt-activation
Project-URL: Repository, https://github.com/gkp1812/rt-activation
Project-URL: Issues, https://github.com/gkp1812/rt-activation/issues
Keywords: keras,tensorflow,activation,neural-networks,deep-learning
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: keras>=3.0.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Dynamic: license-file

# RT Activation

A custom activation function for Keras/TensorFlow implementing Rectified Tanh Activation (RTA).

## Formula
f(x) = max(x, tanh(x))


## Installation

```bash
pip install rt-activation
```

## Usage

### Simple Usage (String-based)

```python
import keras
from keras import layers
import rt_activation  # This registers the activation function

model = keras.Sequential([
    keras.Input(shape=input_shape),
    layers.Conv2D(32, kernel_size=(3, 3), activation="RTA"),
    layers.MaxPooling2D(pool_size=(2, 2)),
    layers.Conv2D(64, kernel_size=(3, 3), activation="RTA"),
    layers.MaxPooling2D(pool_size=(2, 2)),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation="softmax"),
])
```

### Function-based Usage

```python
import keras
from keras import layers
from rt_activation import RTA

model = keras.Sequential([
    keras.Input(shape=input_shape),
    layers.Conv2D(32, kernel_size=(3, 3), activation=RTA),
    layers.MaxPooling2D(pool_size=(2, 2)),
    layers.Conv2D(64, kernel_size=(3, 3), activation=RTA),
    layers.MaxPooling2D(pool_size=(2, 2)),
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation="softmax"),
])
```

## Properties

- **Smooth**: Differentiable everywhere
- **Non-saturating**: Linear growth for large positive values
- **Bounded for negatives**: tanh behavior for negative inputs
- **Zero-centered**: Output can be negative

## License

MIT License
