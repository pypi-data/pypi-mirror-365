# SPADE_LLM Context Management Guide

## Visi√≥n General

La gesti√≥n de contexto en SPADE_LLM controla c√≥mo se mantiene y filtra el historial conversacional entre los agentes y los LLMs. Esta gu√≠a documenta las tres estrategias implementadas: `NoContextManagement`, `WindowSizeContext`, y la nueva `SmartWindowSizeContext`.

## Arquitectura del Sistema de Context Management

### Clase Base: `ContextManagement`

```python
from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Any

class ContextManagement(ABC):
    @abstractmethod
    def apply_context_strategy(self, 
                              messages: List[ContextMessage], 
                              system_prompt: Optional[str] = None) -> List[ContextMessage]:
        """Aplica la estrategia de gesti√≥n de contexto a los mensajes"""
        pass
    
    @abstractmethod
    def get_stats(self, total_messages: int) -> Dict[str, Any]:
        """Obtiene estad√≠sticas sobre la gesti√≥n de contexto"""
        pass
```

## Estrategias Implementadas

### 1. NoContextManagement (Predeterminada)

**Comportamiento:** Mantiene todos los mensajes sin aplicar ning√∫n filtro o limitaci√≥n.

```python
from spade_llm.context import NoContextManagement

context_mgmt = NoContextManagement()
```

**Caracter√≠sticas:**
- ‚úÖ Preserva toda la informaci√≥n conversacional
- ‚úÖ Sin p√©rdida de contexto
- ‚ùå Crecimiento ilimitado de memoria
- ‚ùå Posibles desbordamientos de contexto del LLM

**Casos de uso:**
- Conversaciones cortas (< 10 intercambios)
- Sesiones de depuraci√≥n donde se necesita historial completo
- An√°lisis post-conversaci√≥n

### 2. WindowSizeContext (B√°sica)

**Comportamiento:** Implementa una ventana deslizante que mantiene solo los √∫ltimos N mensajes.

```python
from spade_llm.context import WindowSizeContext

# Mantener √∫ltimos 20 mensajes
context_mgmt = WindowSizeContext(max_messages=20)
```

**Caracter√≠sticas:**
- ‚úÖ Control de memoria predecible
- ‚úÖ Previene desbordamiento de contexto
- ‚ùå P√©rdida de contexto inicial importante
- ‚ùå No diferencia entre tipos de mensajes

**Casos de uso:**
- Conversaciones largas con memoria limitada
- Chatbots con recursos limitados
- Sesiones de monitoreo continuo

### 3. SmartWindowSizeContext (Avanzada) üÜï

**Comportamiento:** Gesti√≥n inteligente que combina ventana deslizante con retenci√≥n selectiva de mensajes cr√≠ticos.

#### Configuraci√≥n B√°sica

```python
from spade_llm.context import SmartWindowSizeContext

# Comportamiento est√°ndar (equivale a WindowSizeContext)
basic_context = SmartWindowSizeContext(max_messages=20)

# Con preservaci√≥n de mensajes iniciales
initial_preserve = SmartWindowSizeContext(
    max_messages=20,
    preserve_initial=3
)

# Con priorizaci√≥n de herramientas
tool_priority = SmartWindowSizeContext(
    max_messages=20,
    prioritize_tools=True
)

# Configuraci√≥n completa
smart_context = SmartWindowSizeContext(
    max_messages=20,
    preserve_initial=3,
    prioritize_tools=True
)
```

#### Par√°metros de Configuraci√≥n

| Par√°metro | Tipo | Default | Descripci√≥n |
|-----------|------|---------|-------------|
| `max_messages` | `int` | 20 | N√∫mero m√°ximo de mensajes en contexto |
| `preserve_initial` | `int` | 0 | N√∫mero de mensajes iniciales a preservar siempre |
| `prioritize_tools` | `bool` | False | Si priorizar resultados de herramientas |

#### Algoritmo de Retenci√≥n Inteligente

```
1. Si total_messages ‚â§ max_messages ‚Üí Retornar todos
2. Si preserve_initial = 0 y prioritize_tools = False ‚Üí Comportamiento b√°sico
3. Si preserve_initial > 0 ‚Üí Preservar iniciales + completar con recientes
4. Si prioritize_tools = True ‚Üí Priorizar tool results + completar espacio
5. Si ambos activos ‚Üí Combinar preservaci√≥n + priorizaci√≥n
```

#### Comportamientos Detallados

##### Preservaci√≥n de Mensajes Iniciales

```python
# Ejemplo: 30 mensajes total, ventana=10, preserve_initial=3
# Resultado: [msg1, msg2, msg3] + [msg24, msg25, ..., msg30]

context = SmartWindowSizeContext(max_messages=10, preserve_initial=3)
```

**Ventaja:** Preserva el objetivo original y contexto fundamental de la conversaci√≥n.

##### Priorizaci√≥n de Herramientas

```python
# Ejemplo: Prioriza todos los mensajes con role="tool"
context = SmartWindowSizeContext(max_messages=15, prioritize_tools=True)
```

**Algoritmo:**
1. Extraer todos los mensajes con `role="tool"`
2. Si tool_messages ‚â• max_messages ‚Üí Tomar √∫ltimos tool_messages
3. Sino ‚Üí tool_messages + mensajes recientes hasta llenar ventana
4. Reordenar cronol√≥gicamente

##### Combinaci√≥n Avanzada

```python
# Preservar contexto inicial + priorizar herramientas
context = SmartWindowSizeContext(
    max_messages=20, 
    preserve_initial=3, 
    prioritize_tools=True
)
```

**Algoritmo:**
1. Reservar espacio para mensajes iniciales
2. Aplicar priorizaci√≥n de herramientas al resto
3. Completar espacio disponible con mensajes recientes

## Casos de Uso Pr√°cticos

### Planificaci√≥n de Viajes

```python
# Preserva destino/fechas + resultados de APIs de hoteles/vuelos
trip_context = SmartWindowSizeContext(
    max_messages=25,
    preserve_initial=4,      # "Viaje a Valencia, 3 d√≠as, 800‚Ç¨, 2 personas"
    prioritize_tools=True    # Resultados de Airbnb, TicketMaster, etc.
)
```

### Revisi√≥n de C√≥digo

```python
# Mantiene requisitos + an√°lisis de herramientas
code_context = SmartWindowSizeContext(
    max_messages=30,
    preserve_initial=2,      # Requisitos y especificaciones
    prioritize_tools=True    # Resultados de linters, tests, an√°lisis
)
```

### Monitoreo de Sistemas

```python
# Configuraci√≥n inicial + estados cr√≠ticos recientes
monitor_context = SmartWindowSizeContext(
    max_messages=15,
    preserve_initial=1,      # Configuraci√≥n de monitoreo
    prioritize_tools=True    # Estados de servicios, m√©tricas cr√≠ticas
)
```

### Investigaci√≥n y An√°lisis

```python
# Pregunta inicial + datos de herramientas de b√∫squeda
research_context = SmartWindowSizeContext(
    max_messages=40,
    preserve_initial=2,      # Pregunta de investigaci√≥n + contexto
    prioritize_tools=True    # Resultados de Wikipedia, DuckDuckGo, APIs
)
```

## Integraci√≥n con LLMAgent

### Configuraci√≥n en Constructor

```python
from spade_llm.agent import LLMAgent
from spade_llm.context import SmartWindowSizeContext

# Crear estrategia de contexto
smart_context = SmartWindowSizeContext(
    max_messages=20,
    preserve_initial=3,
    prioritize_tools=True
)

# Integrar en agente
agent = LLMAgent(
    jid="agent@example.com",
    password="password",
    provider=llm_provider,
    context_management=smart_context,  # ‚Üê Configuraci√≥n aqu√≠
    system_prompt="Eres un asistente con contexto inteligente..."
)
```

### Actualizaci√≥n Din√°mica

```python
# Cambiar estrategia durante ejecuci√≥n
new_context = SmartWindowSizeContext(max_messages=30, preserve_initial=5)
agent.update_context_management(new_context)

# Obtener estad√≠sticas
stats = agent.get_context_stats()
print(f"Mensajes en contexto: {stats['messages_in_context']}")
```

## Estad√≠sticas y Monitoreo

### Obtenci√≥n de Estad√≠sticas

```python
context = SmartWindowSizeContext(
    max_messages=20, 
    preserve_initial=3, 
    prioritize_tools=True
)

# Obtener stats para 50 mensajes totales
stats = context.get_stats(total_messages=50)
```

### Formato de Estad√≠sticas

```python
{
    "strategy": "smart_window_size",
    "max_messages": 20,
    "preserve_initial": 3,
    "prioritize_tools": True,
    "total_messages": 50,
    "messages_in_context": 20,
    "messages_dropped": 30
}
```

## Comparaci√≥n de Estrategias

| Caracter√≠stica | NoContext | WindowSize | SmartWindowSize |
|---------------|-----------|------------|-----------------|
| **Control de memoria** | ‚ùå | ‚úÖ | ‚úÖ |
| **Preserva contexto inicial** | ‚úÖ | ‚ùå | ‚úÖ (opcional) |
| **Prioriza herramientas** | ‚úÖ | ‚ùå | ‚úÖ (opcional) |
| **Complejidad configuraci√≥n** | Ninguna | Baja | Media |
| **Rendimiento** | O(1) | O(1) | O(n log n) |
| **Uso de memoria** | Ilimitado | Limitado | Limitado |

## Mejores Pr√°cticas

### Configuraci√≥n Recomendada por Escenario

**Conversaciones cortas (< 15 mensajes):**
```python
context = NoContextManagement()
```

**Conversaciones largas simples:**
```python
context = WindowSizeContext(max_messages=25)
```

**Workflows complejos con herramientas:**
```python
context = SmartWindowSizeContext(
    max_messages=30,
    preserve_initial=2,
    prioritize_tools=True
)
```

**Sesiones de an√°lisis profundo:**
```python
context = SmartWindowSizeContext(
    max_messages=50,
    preserve_initial=3,
    prioritize_tools=True
)
```

### Configuraci√≥n de preserve_initial

- **preserve_initial=1-2:** Para objetivos simples
- **preserve_initial=3-4:** Para contextos complejos con m√∫ltiples requisitos
- **preserve_initial=5+:** Para especificaciones muy detalladas

### Configuraci√≥n de max_messages

- **10-15:** Para memoria limitada o modelos peque√±os
- **20-30:** Configuraci√≥n est√°ndar recomendada
- **40-60:** Para an√°lisis complejos con muchas herramientas
- **60+:** Solo para casos especiales con modelos grandes

## Ejemplos de C√≥digo Completo

### Ejemplo B√°sico

```python
import asyncio
from spade_llm.agent import LLMAgent, ChatAgent
from spade_llm.context import SmartWindowSizeContext
from spade_llm.providers import LLMProvider

async def main():
    # Configurar contexto inteligente
    smart_context = SmartWindowSizeContext(
        max_messages=20,
        preserve_initial=3,
        prioritize_tools=True
    )
    
    # Crear proveedor
    provider = LLMProvider.create_ollama(
        model="gemma2:2b",
        base_url="http://ollama.gti-ia.upv.es/v1"
    )
    
    # Crear agente con contexto inteligente
    agent = LLMAgent(
        jid="smart_agent@example.com",
        password="password",
        provider=provider,
        context_management=smart_context,
        system_prompt="Asistente con gesti√≥n inteligente de contexto"
    )
    
    await agent.start()
    # ... uso del agente
    await agent.stop()

if __name__ == "__main__":
    asyncio.run(main())
```

### Ejemplo con Monitoreo

```python
async def context_monitoring_example():
    context = SmartWindowSizeContext(
        max_messages=15,
        preserve_initial=2,
        prioritize_tools=True
    )
    
    agent = LLMAgent(
        jid="monitor_agent@example.com",
        password="password",
        provider=provider,
        context_management=context
    )
    
    await agent.start()
    
    # Simular conversaci√≥n larga
    for i in range(25):
        # ... interacciones del agente
        
        # Obtener estad√≠sticas peri√≥dicamente
        if i % 5 == 0:
            stats = agent.get_context_stats()
            print(f"Iteraci√≥n {i}: {stats['messages_in_context']} mensajes en contexto")
    
    await agent.stop()
```

## Futuras Mejoras

### Roadmap de Desarrollo

1. **Context Management basado en tokens** - Gesti√≥n por tokens en lugar de conteo de mensajes
2. **Estrategias sem√°nticas** - Retenci√≥n basada en relevancia sem√°ntica
3. **Context compression** - Compresi√≥n inteligente de mensajes largos
4. **Adaptive windows** - Ventanas que se ajustan din√°micamente
5. **Cross-conversation learning** - Aprendizaje de patrones entre conversaciones

### API Futura Propuesta

```python
# API futura (conceptual)
context = AdaptiveSmartContext(
    token_limit=4000,
    semantic_similarity_threshold=0.8,
    compression_enabled=True,
    adaptive_window=True
)
```

## Conclusi√≥n

La implementaci√≥n de `SmartWindowSizeContext` proporciona un balance √≥ptimo entre control de memoria y preservaci√≥n de informaci√≥n cr√≠tica. Su dise√±o modular permite adaptarse a diferentes escenarios de uso manteniendo la simplicidad de configuraci√≥n y la eficiencia en el rendimiento.

La estrategia es especialmente valiosa en workflows complejos con m√∫ltiples herramientas donde tanto el contexto inicial como los resultados de herramientas son fundamentales para la continuidad de la conversaci√≥n.