[build-system]
requires = ["setuptools>=45", "wheel", "setuptools_scm[toml]>=6.2"]
build-backend = "setuptools.build_meta"

[project]
name = "toxic_detection"
version = "1.0.23"
description = "Intelligent AI Agent for Real-time Content Moderation with 97.5% accuracy"
readme = "README.md"
license = "MIT"
authors = [
    {name = "Yehor Tereshchenko", email = "your.email@example.com"}
]
maintainers = [
    {name = "Yehor Tereshchenko", email = "your.email@example.com"}
]
keywords = [
    "ai",
    "machine-learning", 
    "content-moderation",
    "toxicity-detection",
    "nlp",
    "bert",
    "chat-moderation",
    "gaming",
    "sentiment-analysis",
    "text-classification"
]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Text Processing :: Linguistic",
    "Topic :: Communications :: Chat",
]
requires-python = ">=3.8"
dependencies = [
    "torch>=1.9.0",
    "transformers>=4.20.0",
    "sentence-transformers>=2.2.0",
    "scikit-learn>=1.0.0",
    "numpy>=1.21.0",
    "pandas>=1.3.0",
    "tqdm>=4.62.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=6.0",
    "pytest-cov>=2.0",
    "black>=21.0",
    "flake8>=3.8",
    "mypy>=0.800",
]
gpu = [
    "torch>=1.9.0",
    "torchvision>=0.10.0",
]

[project.urls]
Homepage = "https://github.com/Yegmina/toxic-content-detection-agent"
Documentation = "https://github.com/Yegmina/toxic-content-detection-agent#readme"
Repository = "https://github.com/Yegmina/toxic-content-detection-agent"
"Bug Tracker" = "https://github.com/Yegmina/toxic-content-detection-agent/issues"

[project.scripts]
toxic-validation = "toxic_validation_agent.cli:main"

[project.entry-points."console_scripts"]
toxic-validation = "toxic_validation_agent.cli:main"

[tool.setuptools]
packages = ["toxic_validation_agent"]
include-package-data = true

[tool.setuptools.package-data]
toxic_validation_agent = [
    "toxicity_words.json",
    "config.json",
]

[tool.setuptools_scm]
write_to = "toxic_validation_agent/_version.py"

[tool.black]
line-length = 88
target-version = ['py38', 'py39', 'py310', 'py311', 'py312']

[tool.isort]
profile = "black"
multi_line_output = 3

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short" 