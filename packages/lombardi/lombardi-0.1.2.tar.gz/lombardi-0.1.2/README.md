# Lombardi ğŸ¯

> SQL performance analysis and optimization advisor with SQLMesh integration

[![PyPI version](https://badge.fury.io/py/lombardi.svg)](https://badge.fury.io/py/lombardi)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Lombardi is a powerful SQL performance analysis tool that helps you identify bottlenecks, detect antipatterns, and optimize your queries across different data warehouses. Built on top of SQLGlot's semantic parsing, it provides actionable insights for better query performance.

## âœ¨ Features

### ğŸ” **Semantic SQL Analysis**
- **Complexity Scoring**: Quantitative assessment (0-100) based on joins, subqueries, nesting depth
- **Antipattern Detection**: Identifies common performance killers like SELECT *, cartesian joins, functions in WHERE clauses
- **Optimization Suggestions**: Actionable recommendations with specific examples

### ğŸ¢ **Warehouse-Specific Rules**
- **Snowflake**: Clustering keys, result caching, VARIANT optimization, time travel suggestions
- **BigQuery**: Partitioning recommendations, slot efficiency, materialized views, array operations
- **Universal**: Cross-platform optimizations that work everywhere

### ğŸ› ï¸ **Integration Ready**
- **SQLMesh Integration**: Custom audit for performance checks during `sqlmesh plan`
- **CLI Tool**: Rich terminal output with colors, tables, and formatting
- **Python API**: Programmatic access for custom workflows
- **Multiple Output Formats**: Rich terminal, JSON, plain text

## ğŸš€ Quick Start

### Installation

```bash
pip install lombardi
```

### CLI Usage

```bash
# Analyze a SQL file
lombardi analyze query.sql --dialect snowflake

# Analyze a query string
lombardi analyze --sql "SELECT * FROM orders o JOIN customers c ON o.customer_id = c.id"

# Get just complexity metrics
lombardi complexity --sql "SELECT COUNT(*) FROM large_table WHERE date_col >= '2024-01-01'"

# Export results as JSON
lombardi analyze query.sql --format json > analysis.json

# BigQuery-specific analysis
lombardi analyze --sql "SELECT * FROM dataset.table" --dialect bigquery
```

### Python API

```python
from lombardi import ComplexityAnalyzer, AntipatternDetector, OptimizationSuggester

# Analyze query complexity
analyzer = ComplexityAnalyzer(dialect="snowflake")
metrics = analyzer.analyze("SELECT * FROM orders JOIN customers ON orders.customer_id = customers.id")

print(f"Complexity Score: {metrics.complexity_score}/100")
print(f"Join Count: {metrics.join_count}")
print(f"Subqueries: {metrics.subquery_count}")

# Detect antipatterns
detector = AntipatternDetector()
issues = detector.detect("SELECT * FROM users WHERE UPPER(name) = 'JOHN'")

for issue in issues:
    print(f"âŒ {issue.pattern}: {issue.description}")

# Get optimization suggestions
suggester = OptimizationSuggester(dialect="bigquery")
suggestions = suggester.suggest("SELECT * FROM large_table WHERE date_col >= '2024-01-01'")

for suggestion in suggestions:
    print(f"ğŸ’¡ {suggestion.title}: {suggestion.description}")
```

## ğŸ“Š Example Output

```bash
$ lombardi analyze --sql "SELECT * FROM orders o JOIN customers c ON o.customer_id = c.id WHERE UPPER(c.name) LIKE '%ACME%'"
```

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SQL Analysis Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Complexity Score: 12.0/100                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

    Complexity Metrics    
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Metric         â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ Join Count     â”‚ 1     â”‚
â”‚ Subquery Count â”‚ 0     â”‚
â”‚ CTE Count      â”‚ 0     â”‚
â”‚ Function Count â”‚ 1     â”‚
â”‚ Nesting Depth  â”‚ 0     â”‚
â”‚ Table Count    â”‚ 2     â”‚
â”‚ Column Count   â”‚ 3     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

                                Detected Issues                                 
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Pattern                     â”ƒ Severity â”ƒ Description                         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Select Star                 â”‚ MEDIUM   â”‚ SELECT * can be inefficient        â”‚
â”‚ Function On Column In Where â”‚ HIGH     â”‚ Functions prevent index usage      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                            Optimization Suggestions                            
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Category    â”ƒ Priority â”ƒ Suggestion                                          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Performance â”‚ HIGH     â”‚ Function On Column In Where: Rewrite to avoid      â”‚
â”‚             â”‚          â”‚ applying functions to indexed columns               â”‚
â”‚ Indexing    â”‚ HIGH     â”‚ JOIN Index Optimization: Ensure indexes exist on   â”‚
â”‚             â”‚          â”‚ JOIN columns: o.customer_id, c.id                  â”‚
â”‚ Performance â”‚ MEDIUM   â”‚ Select Star: Explicitly list required columns      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”Œ SQLMesh Integration

Integrate Lombardi into your SQLMesh workflow for automated performance checks:

```python
# In your SQLMesh model
MODEL (
  name my_project.optimized_table,
  kind FULL,
  audits [performance_check]
);

SELECT 
  region_code,
  species_code,
  COUNT(*) as observation_count
FROM @DEV.my_project.raw_observations 
WHERE observation_date >= '2024-01-01'
GROUP BY 1, 2;
```

```python
# Configure the audit
from lombardi.integrations.sqlmesh_audit import create_performance_audit

performance_audit = create_performance_audit(
    complexity_threshold=30.0,
    min_severity="medium",
    dialect="snowflake"
)
```

## ğŸ—ï¸ Architecture

```
lombardi/
â”œâ”€â”€ analyzers/           # Core analysis engines
â”‚   â”œâ”€â”€ complexity_analyzer.py      # Complexity scoring
â”‚   â”œâ”€â”€ antipattern_detector.py     # Antipattern detection  
â”‚   â””â”€â”€ optimization_suggester.py   # Optimization recommendations
â”œâ”€â”€ rules/               # Warehouse-specific optimizations
â”‚   â”œâ”€â”€ snowflake_rules.py          # Snowflake optimizations
â”‚   â””â”€â”€ bigquery_rules.py           # BigQuery optimizations
â”œâ”€â”€ integrations/        # Third-party integrations
â”‚   â””â”€â”€ sqlmesh_audit.py            # SQLMesh audit integration
â””â”€â”€ cli.py              # Command-line interface
```

## ğŸ¯ Detected Antipatterns

Lombardi identifies these common SQL performance issues:

| Pattern | Severity | Description |
|---------|----------|-------------|
| **SELECT *** | Medium | Can be inefficient and fragile |
| **Cartesian Joins** | Critical | Missing JOIN conditions |
| **Functions in WHERE** | High | Prevents index usage |
| **Leading Wildcards** | Medium | `LIKE '%pattern'` prevents indexes |
| **Missing WHERE** | Medium | Full table scans |
| **Subquery in SELECT** | Medium | Often better as JOINs |

## ğŸ¢ Warehouse-Specific Optimizations

### Snowflake
- â„ï¸ **Clustering Keys**: Recommendations for large table partitioning
- ğŸš€ **Result Caching**: Identify cacheable query patterns  
- ğŸ“Š **Warehouse Sizing**: Complexity-based sizing suggestions
- ğŸ•’ **Time Travel**: Optimize historical queries
- ğŸ“„ **VARIANT**: Semi-structured data query optimization

### BigQuery
- ğŸ“… **Partitioning**: Date/timestamp partitioning opportunities
- ğŸ—‚ï¸ **Clustering**: Multi-column clustering recommendations
- ğŸ’° **Slot Efficiency**: Cost optimization suggestions
- ğŸ”„ **Materialized Views**: Pre-aggregation opportunities
- ğŸ“Š **Array Operations**: UNNEST and array function optimization

## ğŸ”§ Configuration

### CLI Options

```bash
lombardi analyze [OPTIONS] [SQL_FILE]

Options:
  --sql, -s TEXT              SQL query string to analyze
  --dialect, -d TEXT          SQL dialect (snowflake, bigquery, etc.)
  --threshold, -t FLOAT       Complexity threshold (0-100) [default: 50.0]
  --severity TEXT             Minimum severity (low, medium, high, critical) [default: medium]
  --format, -f TEXT           Output format (rich, json, plain) [default: rich]
  --suggestions/--no-suggestions  Include optimization suggestions [default: suggestions]
```

### Python API Configuration

```python
# Initialize with specific dialect
analyzer = ComplexityAnalyzer(dialect="snowflake")
detector = AntipatternDetector(dialect="bigquery")

# Configure thresholds and rules
suggester = OptimizationSuggester(dialect="snowflake")
suggestions = suggester.suggest(sql_query)

# Warehouse-specific analysis
from lombardi.rules.snowflake_rules import SnowflakeRules
snowflake_rules = SnowflakeRules()
sf_suggestions = snowflake_rules.analyze(sql_query)
```

## ğŸ§ª Development

### Setup

```bash
git clone https://github.com/Doctacon/lombardi.git
cd lombardi
uv sync
```

### Testing

```bash
# Run tests
uv run pytest tests/ -v

# Test CLI
uv run lombardi analyze --sql "SELECT * FROM test_table"

# Test with coverage
uv run pytest tests/ --cov=lombardi
```

### Building

```bash
# Build package
uv build

# Test locally
pip install dist/lombardi-*.whl
```

## ğŸ“ˆ Performance Impact

Lombardi helps identify optimizations that can provide:

- **Query Speed**: 10x-100x faster execution through proper indexing
- **Cost Reduction**: 50-90% lower warehouse costs via efficient queries  
- **Resource Usage**: Reduced CPU, memory, and I/O through better query patterns
- **Maintainability**: Cleaner, more readable SQL through antipattern detection

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and add tests
4. Run tests: `uv run pytest`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **SQLGlot**: Powers our semantic SQL parsing
- **SQLMesh**: Inspiration for the audit integration pattern
- **Rich**: Beautiful terminal output
- **Typer**: Excellent CLI framework

## ğŸ”— Links

- **Documentation**: [Coming Soon]
- **PyPI**: https://pypi.org/project/lombardi/
- **Issues**: https://github.com/Doctacon/lombardi/issues
- **Discussions**: https://github.com/Doctacon/lombardi/discussions

---

*Named after [Vince Lombardi](https://en.wikipedia.org/wiki/Vince_Lombardi), who believed "Perfection is not attainable, but if we chase perfection we can catch excellence" - the same philosophy we apply to SQL optimization.*