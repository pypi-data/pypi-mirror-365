{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881c0502",
   "metadata": {},
   "source": [
    "# Sales Forecasting with Coptic Library\n",
    "\n",
    "This notebook demonstrates how to use the Coptic forecasting library for time series prediction. We'll walk through the complete process from data loading to model evaluation.\n",
    "\n",
    "## What we'll cover:\n",
    "1. Loading and exploring sample sales data\n",
    "2. Data cleaning and preprocessing\n",
    "3. Training different forecasting models\n",
    "4. Generating forecasts\n",
    "5. Evaluating model performance\n",
    "6. Comparing multiple models\n",
    "7. Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de3267",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import coptic library\n",
    "from coptic import CopticForecaster\n",
    "from coptic.preprocessing import DataCleaner, FeatureGenerator\n",
    "from coptic.utils.metrics import calculate_metrics, forecast_accuracy_summary\n",
    "from coptic.utils.plot import plot_forecast, plot_multiple_forecasts\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1107e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample sales data\n",
    "df = pd.read_csv('../datasets/sample_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df['date'], df['sales'], linewidth=1.5)\n",
    "plt.title('Daily Sales Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Sales Statistics:\")\n",
    "print(df['sales'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7aa6d",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data cleaner\n",
    "cleaner = DataCleaner(\n",
    "    remove_outliers=False,  # We'll check for outliers first\n",
    "    fill_method='interpolate'\n",
    ")\n",
    "\n",
    "# Get data quality report\n",
    "quality_report = cleaner.get_data_quality_report(df, 'date', 'sales')\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "print(f\"Total rows: {quality_report['dataset_info']['total_rows']}\")\n",
    "print(f\"Missing values in sales: {quality_report['missing_values']['target_missing']}\")\n",
    "print(f\"Duplicate dates: {quality_report['duplicates']['duplicate_dates']}\")\n",
    "print(f\"\\nOutlier detection (IQR method):\")\n",
    "print(f\"Number of outliers: {quality_report['outliers']['iqr_outliers']['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data (minimal cleaning since our sample data is already clean)\n",
    "df_clean = cleaner.clean(df, 'date', 'sales')\n",
    "\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"Cleaned data shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b276ab0",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split\n",
    "\n",
    "For time series, we need to split the data chronologically to maintain temporal order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39028cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% for training, 20% for testing\n",
    "split_idx = int(len(df_clean) * 0.8)\n",
    "\n",
    "train_df = df_clean[:split_idx].copy()\n",
    "test_df = df_clean[split_idx:].copy()\n",
    "\n",
    "print(f\"Training data: {len(train_df)} samples\")\n",
    "print(f\"Test data: {len(test_df)} samples\")\n",
    "print(f\"Training period: {train_df['date'].min()} to {train_df['date'].max()}\")\n",
    "print(f\"Test period: {test_df['date'].min()} to {test_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84270a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train-test split\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_df['date'], train_df['sales'], label='Training', color='blue')\n",
    "plt.plot(test_df['date'], test_df['sales'], label='Test', color='orange')\n",
    "plt.axvline(x=train_df['date'].max(), color='red', linestyle='--', alpha=0.7, label='Split Point')\n",
    "plt.title('Train-Test Split')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc46e6",
   "metadata": {},
   "source": [
    "## 4. Model Training and Forecasting\n",
    "\n",
    "We'll train multiple models and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1817a",
   "metadata": {},
   "source": [
    "### 4.1 Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_forecaster = CopticForecaster(\n",
    "    model_type=\"randomforest\",\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_forecaster.fit(train_df, date_col='date', target_col='sales')\n",
    "\n",
    "# Generate forecasts for the test period\n",
    "rf_forecast = rf_forecaster.predict(periods=len(test_df), freq='D')\n",
    "\n",
    "print(f\"Generated {len(rf_forecast)} forecasts\")\n",
    "rf_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Random Forest results\n",
    "fig = rf_forecaster.plot(figsize=(15, 8))\n",
    "plt.title('Random Forest Forecast')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "rf_forecaster.plot_feature_importance(top_n=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac35b66",
   "metadata": {},
   "source": [
    "### 4.2 XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "xgb_forecaster = CopticForecaster(\n",
    "    model_type=\"xgboost\",\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_forecaster.fit(train_df, date_col='date', target_col='sales')\n",
    "\n",
    "# Generate forecasts\n",
    "xgb_forecast = xgb_forecaster.predict(periods=len(test_df), freq='D')\n",
    "\n",
    "print(f\"Generated {len(xgb_forecast)} forecasts\")\n",
    "xgb_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot XGBoost results\n",
    "fig = xgb_forecaster.plot(figsize=(15, 8))\n",
    "plt.title('XGBoost Forecast')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "xgb_forecaster.plot_feature_importance(top_n=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fec87e",
   "metadata": {},
   "source": [
    "### 4.3 Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Prophet model\n",
    "prophet_forecaster = CopticForecaster(\n",
    "    model_type=\"prophet\",\n",
    "    seasonality_mode='additive',\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "print(\"Training Prophet model...\")\n",
    "prophet_forecaster.fit(train_df, date_col='date', target_col='sales')\n",
    "\n",
    "# Generate forecasts\n",
    "prophet_forecast = prophet_forecaster.predict(periods=len(test_df), freq='D')\n",
    "\n",
    "print(f\"Generated {len(prophet_forecast)} forecasts\")\n",
    "prophet_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet results\n",
    "fig = prophet_forecaster.plot(figsize=(15, 8))\n",
    "plt.title('Prophet Forecast')\n",
    "plt.show()\n",
    "\n",
    "# Plot Prophet components\n",
    "prophet_forecaster.plot_components(figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731ec86",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Let's evaluate each model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_metrics = rf_forecaster.evaluate(test_df)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(forecast_accuracy_summary(rf_metrics))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_metrics = xgb_forecaster.evaluate(test_df)\n",
    "print(\"XGBoost Performance:\")\n",
    "print(forecast_accuracy_summary(xgb_metrics))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f976388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Prophet\n",
    "prophet_metrics = prophet_forecaster.evaluate(test_df)\n",
    "print(\"Prophet Performance:\")\n",
    "print(forecast_accuracy_summary(prophet_metrics))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df8831",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bb096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Random Forest': rf_metrics,\n",
    "    'XGBoost': xgb_metrics,\n",
    "    'Prophet': prophet_metrics\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data).T\n",
    "\n",
    "# Select key metrics for comparison\n",
    "key_metrics = ['mae', 'rmse', 'mape', 'r2']\n",
    "comparison_summary = comparison_df[key_metrics].round(4)\n",
    "\n",
    "print(\"Model Comparison Summary:\")\n",
    "print(comparison_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eaa554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics_to_plot = ['mae', 'rmse', 'mape', 'r2']\n",
    "titles = ['Mean Absolute Error (MAE)', 'Root Mean Square Error (RMSE)', \n",
    "          'Mean Absolute Percentage Error (MAPE)', 'R-squared']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics_to_plot, titles)):\n",
    "    ax = axes[i//2, i%2]\n",
    "    comparison_summary[metric].plot(kind='bar', ax=ax, color=['skyblue', 'lightgreen', 'coral'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(metric.upper())\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c038b5a",
   "metadata": {},
   "source": [
    "## 7. Visualize All Forecasts Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b58adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all forecasts visually\n",
    "forecasts_dict = {\n",
    "    'Random Forest': rf_forecast,\n",
    "    'XGBoost': xgb_forecast,\n",
    "    'Prophet': prophet_forecast\n",
    "}\n",
    "\n",
    "fig = plot_multiple_forecasts(\n",
    "    train_df, \n",
    "    forecasts_dict, \n",
    "    date_col='date', \n",
    "    target_col='sales',\n",
    "    title='Model Comparison - All Forecasts',\n",
    "    figsize=(18, 8)\n",
    ")\n",
    "\n",
    "# Add actual test values for comparison\n",
    "plt.plot(test_df['date'], test_df['sales'], \n",
    "         label='Actual Test', color='black', linewidth=2, linestyle='--')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd0117",
   "metadata": {},
   "source": [
    "## 8. Future Forecasting\n",
    "\n",
    "Now let's use the best performing model to generate future forecasts beyond our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63424365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best model based on RMSE\n",
    "best_model_name = comparison_summary['rmse'].idxmin()\n",
    "print(f\"Best performing model: {best_model_name} (RMSE: {comparison_summary.loc[best_model_name, 'rmse']:.2f})\")\n",
    "\n",
    "# Select the best model\n",
    "if best_model_name == 'Random Forest':\n",
    "    best_model = rf_forecaster\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb_forecaster\n",
    "else:\n",
    "    best_model = prophet_forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97da479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain best model on full dataset\n",
    "print(f\"Retraining {best_model_name} on full dataset...\")\n",
    "best_model.fit(df_clean, date_col='date', target_col='sales')\n",
    "\n",
    "# Generate 30-day future forecast\n",
    "future_forecast = best_model.predict(periods=30, freq='D')\n",
    "\n",
    "print(f\"Generated 30-day future forecast\")\n",
    "print(f\"Forecast period: {future_forecast['date'].min()} to {future_forecast['date'].max()}\")\n",
    "future_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aad6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot future forecast\n",
    "fig = best_model.plot(figsize=(18, 8))\n",
    "plt.title(f'{best_model_name} - 30-Day Future Forecast')\n",
    "plt.show()\n",
    "\n",
    "# Print forecast statistics\n",
    "print(\"Future Forecast Statistics:\")\n",
    "print(f\"Mean forecasted sales: ${future_forecast['yhat'].mean():.2f}\")\n",
    "print(f\"Min forecasted sales: ${future_forecast['yhat'].min():.2f}\")\n",
    "print(f\"Max forecasted sales: ${future_forecast['yhat'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d8e42",
   "metadata": {},
   "source": [
    "## 9. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model for future use\n",
    "model_filename = f'best_sales_forecaster_{best_model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "best_model.save(model_filename)\n",
    "\n",
    "print(f\"Best model saved as: {model_filename}\")\n",
    "\n",
    "# Show model information\n",
    "model_info = best_model.get_model_info()\n",
    "print(\"\\nModel Information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58ade8",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "In this notebook, we demonstrated the complete workflow for time series forecasting using the Coptic library:\n",
    "\n",
    "1. **Data Loading and Exploration**: We loaded sample sales data and explored its characteristics\n",
    "2. **Data Quality Assessment**: Used built-in tools to check for missing values, outliers, and data quality issues\n",
    "3. **Model Training**: Trained three different forecasting models (Random Forest, XGBoost, Prophet)\n",
    "4. **Model Evaluation**: Compared models using comprehensive metrics including MAE, RMSE, MAPE, and R²\n",
    "5. **Future Forecasting**: Used the best-performing model to generate future predictions\n",
    "6. **Model Persistence**: Saved the trained model for future use\n",
    "\n",
    "### Key Takeaways:\n",
    "- The Coptic library provides a unified interface for multiple forecasting algorithms\n",
    "- Automatic feature engineering saves time and improves model performance\n",
    "- Built-in evaluation metrics make model comparison straightforward\n",
    "- Visualization tools help understand model behavior and forecast quality\n",
    "\n",
    "### Next Steps:\n",
    "- Try different model parameters for optimization\n",
    "- Experiment with custom feature engineering\n",
    "- Use cross-validation for more robust model evaluation\n",
    "- Implement automated model selection and hyperparameter tuning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
