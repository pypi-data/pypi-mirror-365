# Industrial-Grade Slider CAPTCHA Recognition System

<div align="center">

[English](https://github.com/TomokotoKiyoshi/Sider_CAPTCHA_Solver/blob/main/README.md) | [ç®€ä½“ä¸­æ–‡](https://github.com/TomokotoKiyoshi/Sider_CAPTCHA_Solver/blob/main/README_zh.md)

</div>

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![PyPI version](https://badge.fury.io/py/sider-captcha-solver.svg)](https://pypi.org/project/sider-captcha-solver/)
[![GitHub version](https://img.shields.io/badge/GitHub-v1.0.3-blue.svg)](https://github.com/TomokotoKiyoshi/Sider_CAPTCHA_Solver)

A high-precision slider CAPTCHA recognition solution based on deep learning, utilizing an improved CenterNet architecture to achieve 85%+ accuracy on real CAPTCHA datasets.

**Latest Version**: v1.0.3

</div>

## ðŸ†• What's New

### v1.0.3 (2025-07-27) - Latest Version
- ðŸ›¡ï¸ **Enhanced Anti-Confusion Features**:
  - Gap rotation (0.5-1.8Â° random rotation, 50% probability)
  - Perlin noise on sliders (40-80% intensity, 50% probability)
  - Confusing gaps (Â±10-30Â° rotation, 60% probability)
  - Gap highlighting effects (30% probability)
- ðŸ“Š **Improved Model Performance**:
  - **85%+ accuracy** on real CAPTCHAs with enhanced robustness
  - Better performance against adversarial examples
  - More stable predictions under complex scenarios
- ðŸ”§ **Package Improvements**:
  - Optimized model loading
  - Better error handling

### v1.0.2 (2025-07-21) - Initial Release
- ðŸš€ Initial public release
- ðŸ“¦ Basic slider CAPTCHA recognition
- ðŸŽ¯ 80% accuracy on real CAPTCHAs with 7px error tolerance
- ðŸ’¡ Support for 11 puzzle shapes (5 regular + 6 special)
- âš¡ Fast inference: GPU 1.30ms, CPU 5.21ms

## ðŸ“‘ Table of Contents

- [ðŸ“‹ Project Overview](#-project-overview)
  - [ðŸŽ¯ Core Features](#-core-features)
  - [ðŸ–¼ï¸ Recognition Performance Demo](#ï¸-recognition-performance-demo)
- [ðŸš€ Quick Start](#-quick-start)
  - [Requirements](#requirements)
  - [Installation](#installation)
  - [Basic Usage](#basic-usage)
- [ðŸ“Š Data Generation Process](#-data-generation-process)
- [ðŸ—ï¸ Network Architecture](#ï¸-network-architecture)
- [ðŸ“ˆ Performance Metrics](#-performance-metrics)
- [ðŸ› ï¸ Main Features](#ï¸-main-features)
- [âš ï¸ Disclaimer](#ï¸-disclaimer)
- [ðŸ“ Project Structure](#-project-structure)
- [ðŸ”§ Tech Stack](#-tech-stack)
- [ðŸ“ž Contact](#-contact)

## ðŸ“‹ Project Overview

This project is an industrial-grade slider CAPTCHA recognition system that overcomes the accuracy bottleneck of traditional template matching algorithms through deep learning methods. The system is trained on **over 300,000** synthetic CAPTCHA images, employing a lightweight CNN architecture that ensures high precision while maintaining real-time inference capabilities.

### ðŸŽ¯ Core Features

- **High-Precision Recognition**: 85%+ accuracy with 7px error tolerance on real CAPTCHAs (v1.0.3)
- **Enhanced Anti-Confusion**: Supports rotated gaps, Perlin noise on sliders, confusing gaps, and gap highlighting effects
- **Real-Time Inference**: GPU inference 1.30ms (RTX 5090), CPU inference 5.21ms (AMD Ryzen 9 9950X), supporting real-time applications
- **Lightweight Architecture**: Only 3.5M parameters, model file approximately 36MB
- **Industrial-Grade Design**: Complete data generation, training, and evaluation pipeline
- **Sub-pixel Precision**: Achieves sub-pixel level localization using CenterNet offset mechanism

### ðŸ–¼ï¸ Recognition Performance Demo

#### Real CAPTCHA Dataset Recognition Results

![Real Dataset Recognition Results](https://github.com/TomokotoKiyoshi/Sider_CAPTCHA_Solver/blob/main/results/1.0.1/best_model_evaluation/real_captchas/visualizations/sample_0031.png?raw=true)

*Figure: Recognition results on real website CAPTCHAs, with red circles marking gap positions and blue circles marking slider positions*

#### Test Dataset Recognition Results

![Test Dataset Recognition Results](https://github.com/TomokotoKiyoshi/Sider_CAPTCHA_Solver/blob/main/results/1.0.1/best_model_evaluation/test_dataset/visualizations/sample_0014.png?raw=true)

*Figure: Recognition results on synthetic test set, demonstrating the model's adaptability to different shapes and lighting conditions*

## ðŸš€ Quick Start

### Requirements

```bash
# Python 3.8+
pip install -r requirements.txt
```

### Installation

#### Install via pip

```bash
pip install sider-captcha-solver  # Install v1.0.3 from PyPI
```

### Basic Usage

After pip installation, you can directly import and use:

#### 1. Basic Prediction - Get Sliding Distance

```python
from sider_captcha_solver import CaptchaPredictor

# Initialize predictor
predictor = CaptchaPredictor(
    model_path='best',  # Use built-in best model, or specify custom model path
    device='auto'       # Auto-select GPU/CPU
)

# Predict single image
result = predictor.predict('path/to/captcha.png')

# Get sliding distance
if result['slider_x'] and result['gap_x']:
    sliding_distance = result['gap_x'] - result['slider_x']
    print(f"Sliding distance: {sliding_distance:.2f} px")
    print(f"Gap position: ({result['gap_x']:.2f}, {result['gap_y']:.2f})")
    print(f"Slider position: ({result['slider_x']:.2f}, {result['slider_y']:.2f})")
else:
    print("Detection failed")
```

#### 2. Batch Processing - Process Multiple Images

```python
from sider_captcha_solver import CaptchaPredictor
import glob
import os

# Initialize predictor
predictor = CaptchaPredictor(model_path='best', device='auto')

# Batch process CAPTCHAs
captcha_folder = 'path/to/captchas'

for img_path in glob.glob(os.path.join(captcha_folder, '*.png')):
    result = predictor.predict(img_path)

    if result['slider_x'] and result['gap_x']:
        distance = result['gap_x'] - result['slider_x']
        confidence = (result['slider_confidence'] + result['gap_confidence']) / 2
        print(f"{os.path.basename(img_path)}: Slide {distance:.1f} px (Confidence: {confidence:.3f})")
    else:
        print(f"{os.path.basename(img_path)}: Detection failed")
```

#### 3. Visualization and Debugging

```python
from sider_captcha_solver import CaptchaPredictor
import matplotlib.pyplot as plt

# Initialize predictor
predictor = CaptchaPredictor(model_path='best', device='auto')

# Test image path
test_image = 'path/to/captcha.png'

# Generate and save prediction visualization
predictor.visualize_prediction(
    test_image,
    save_path='prediction_result.png',  # Save path
    show=True                           # Display window
)

# Generate heatmap visualization (view model internal activations)
predictor.visualize_heatmaps(
    test_image,
    save_path='heatmap_result.png',    # Save 4-panel heatmap
    show=True
)

# Compare different threshold effects
thresholds = [0.0, 0.1, 0.3, 0.5]
fig, axes = plt.subplots(1, len(thresholds), figsize=(15, 4))

for idx, threshold in enumerate(thresholds):
    # Create predictor with different thresholds
    pred = CaptchaPredictor(model_path='best', hm_threshold=threshold)
    result = pred.predict(test_image)

    # Visualize to subplot
    ax = axes[idx]
    img = plt.imread(test_image)
    ax.imshow(img)
    ax.set_title(f'Threshold={threshold}')

    if result['slider_x'] and result['gap_x']:
        ax.plot(result['slider_x'], result['slider_y'], 'bo', markersize=10)
        ax.plot(result['gap_x'], result['gap_y'], 'ro', markersize=10)
    ax.axis('off')

plt.tight_layout()
plt.savefig('threshold_comparison.png')
plt.show()
```

#### 4. Complete Production Environment Example

```python
from sider_captcha_solver import CaptchaPredictor
import logging
import time
from typing import Optional, Dict

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CaptchaSolver:
    """Production environment CAPTCHA solver wrapper"""

    def __init__(self, model_path: str = 'best', device: str = 'auto'):
        self.predictor = CaptchaPredictor(
            model_path=model_path,
            device=device,
            hm_threshold=0.1  # Balance accuracy and recall
        )
        logger.info(f"CAPTCHA solver initialized, device: {device}")

    def solve(self, image_path: str, max_retries: int = 3) -> Optional[Dict]:
        """
        Solve CAPTCHA with retry mechanism

        Args:
            image_path: CAPTCHA image path
            max_retries: Maximum retry attempts

        Returns:
            Dictionary containing sliding distance and confidence, None on failure
        """
        for attempt in range(max_retries):
            try:
                # Record start time
                start_time = time.time()

                # Execute prediction
                result = self.predictor.predict(image_path)

                # Calculate elapsed time
                elapsed_time = (time.time() - start_time) * 1000

                # Check result validity
                if result['slider_x'] and result['gap_x']:
                    sliding_distance = result['gap_x'] - result['slider_x']
                    confidence = (result['slider_confidence'] + result['gap_confidence']) / 2

                    logger.info(f"Solve success: distance={sliding_distance:.1f}px, "
                              f"confidence={confidence:.3f}, time={elapsed_time:.1f}ms")

                    return {
                        'success': True,
                        'sliding_distance': sliding_distance,
                        'confidence': confidence,
                        'elapsed_ms': elapsed_time,
                        'details': result
                    }
                else:
                    logger.warning(f"Attempt {attempt + 1} failed: no valid result detected")

            except Exception as e:
                logger.error(f"Attempt {attempt + 1} error: {str(e)}")

            # Brief delay if not last attempt
            if attempt < max_retries - 1:
                time.sleep(0.1)

        logger.error(f"Solve failed: reached maximum retries {max_retries}")
        return None

# Usage example
if __name__ == "__main__":
    solver = CaptchaSolver()

    # Solve single CAPTCHA
    result = solver.solve('path/to/captcha.png')

    if result and result['success']:
        print(f"Sliding distance: {result['sliding_distance']:.1f} px")
        print(f"Confidence: {result['confidence']:.3f}")
        print(f"Processing time: {result['elapsed_ms']:.1f} ms")
    else:
        print("CAPTCHA solving failed")
```

### Advanced Features

#### 1. Custom Model and Configuration

```python
from sider_captcha_solver import CaptchaPredictor
import torch

# Use your own trained model
custom_predictor = CaptchaPredictor(
    model_path='path/to/your_trained_model.pth',
    device='cuda:0',    # Specify GPU
    hm_threshold=0.15   # Adjust based on model characteristics
)

# Check model info
if torch.cuda.is_available():
    print(f"Using GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM usage: {torch.cuda.memory_allocated(0) / 1024**2:.1f} MB")

# Predict
result = custom_predictor.predict('captcha.png')
```

#### 2. Performance Benchmarking

```python
from sider_captcha_solver import CaptchaPredictor
import time
import numpy as np

# Initialize predictor
predictor = CaptchaPredictor(model_path='best', device='auto')

# Test image list
test_images = ['captcha1.png', 'captcha2.png', 'captcha3.png']

# Warm up (first inference is slower)
_ = predictor.predict(test_images[0])

# Performance test
times = []
for _ in range(10):  # Test each image 10 times
    for img_path in test_images:
        start = time.time()
        result = predictor.predict(img_path)
        elapsed = (time.time() - start) * 1000  # Convert to milliseconds
        times.append(elapsed)

# Statistics
print(f"Average inference time: {np.mean(times):.2f} ms")
print(f"Fastest: {np.min(times):.2f} ms")
print(f"Slowest: {np.max(times):.2f} ms")
print(f"Std deviation: {np.std(times):.2f} ms")
print(f"FPS: {1000 / np.mean(times):.1f}")
```

## ðŸ“Š Data Generation Process

### 1. Data Collection

Downloaded high-quality images from Pixabay across 10 categories as backgrounds: Minecraft, Pixel Food, Block Public Square, Block Illustration, Backgrounds, Buildings, Nature, Anime Cityscape, Abstract Geometric Art, etc. Up to 200 images per category, totaling approximately 2,000 raw images.

### 2. CAPTCHA Generation Logic

```
Raw Images (2000+) â†’ Resize(320Ã—160) â†’ Puzzle Generation
                                        â†“
                              11 shapes Ã— 3 sizes Ã— 4 positions
                                        â†“
                              132 CAPTCHAs per original image
                                        â†“
                              Total: 354,024 training images generated
```

**Puzzle Shape Design**:

- 5 regular puzzle shapes (combinations of convex, concave, and flat edges)
- 6 special shapes (circle, square, triangle, hexagon, pentagon, star)

**Random Parameters**:

- Puzzle size: 40-70 pixels (3 random sizes)
- Position distribution: x-axis beyond slider width + 10px to avoid overlap
- Lighting effects: Randomly added lighting variations for robustness

### 3. Dataset Split

- Training set: 90% (split by original images to avoid data leakage)
- Test set: 10% (Test Set 1)
- Real CAPTCHA test set: 100 NetEase Yidun CAPTCHAs (Test Set 2)

## ðŸ—ï¸ Network Architecture

### Model Structure

```
Input (3Ã—160Ã—320)
    â”‚
    â”œâ”€ Stem Conv (3Ã—3, stride=2) â”€â”€â”€â”€â”€â”€â†’ 32Ã—80Ã—160
    â”‚
    â”œâ”€ ResBlock Stage-1 (Ã—2, stride=2) â”€â†’ 64Ã—40Ã—80
    â”‚
    â”œâ”€ ResBlock Stage-2 (Ã—2, stride=2) â”€â†’ 128Ã—20Ã—40
    â”‚
    â”œâ”€ ResBlock Stage-3 (Ã—2, stride=2) â”€â†’ 256Ã—10Ã—20
    â”‚
    â”œâ”€ Neck (1Ã—1 Conv) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ 128Ã—10Ã—20
    â”‚
    â”œâ”€ UpConv-1 (3Ã—3, stride=2) â”€â”€â”€â”€â”€â”€â”€â”€â†’ 64Ã—20Ã—40
    â”‚
    â”œâ”€ UpConv-2 (3Ã—3, stride=2) â”€â”€â”€â”€â”€â”€â”€â”€â†’ 64Ã—40Ã—80
    â”‚
    â””â”€â”¬â”€ Gap Detection Head â”€â”€â”€â”€â”
        â”‚   â”œâ”€ Heatmap (1Ã—40Ã—80)   â”‚
        â”‚   â””â”€ Offset (2Ã—40Ã—80)    â”‚
        â”‚                              â”‚
        â””â”€ Piece Detection Head â”€â”€â”€â”¤
             â”œâ”€ Heatmap (1Ã—40Ã—80)   â”‚
             â””â”€ Offset (2Ã—40Ã—80)    â”‚
```

### Key Design Elements

- **Backbone**: ResNet18-Lite, removed global pooling and fully connected layers
- **Detection Heads**: Dual-branch CenterNet design, detecting gap and slider centers separately
- **Loss Function**: Focal Loss (heatmap) + L1 Loss (offset regression)
- **Downsampling Rate**: 4x, output resolution 80Ã—40
- **Activation**: ReLU (except output layers)
- **Normalization**: BatchNorm

### Model Parameters

| Component       | Parameters | Description       |
| --------------- | ---------- | ----------------- |
| Backbone        | ~3.0M      | ResNet18-Lite     |
| Neck + UpConv   | ~0.3M      | Feature fusion    |
| Detection Heads | ~0.2M      | Dual-branch heads |
| **Total**       | **~3.5M**  | FP32 ~36MB        |

## ðŸ“ˆ Performance Metrics

### Accuracy (Based on Sliding Distance Error)

| Dataset              | 5px Threshold | 7px Threshold | Best Epoch |
| -------------------- | ------------- | ------------- | ---------- |
| Test Set (Synthetic) | 99.4%         | 99.4%         | 16         |
| Real CAPTCHAs        | **73%**       | **80%**       | 15/16      |

### Inference Performance

| Hardware          | Inference Time | FPS | Batch (Ã—32) |
| ----------------- | -------------- | --- | ----------- |
| RTX 5090          | 1.30ms         | 771 | 11.31ms     |
| AMD Ryzen 9 9950X | 5.21ms         | 192 | 144.89ms    |

### Mean Absolute Error (MAE)

- Test set: Slider 0.30px, Gap 1.14px
- Real CAPTCHAs: Slider 2.84px, Gap 9.98px

## ðŸ› ï¸ Main Features

### 1. Data Generation

- Auto-download Pixabay images
- Batch generate slider CAPTCHAs
- Support multiple puzzle shapes

### 2. Model Training

- Automatic learning rate scheduling
- Training process visualization

### 3. Inference Deployment

- Support batch prediction
- REST API interface
- Heatmap visualization support

### 4. Evaluation Analysis

- Training curve analysis

## âš ï¸ Disclaimer

**This project is for learning and research purposes only. Commercial or illegal use is prohibited.**

1. This project aims to promote academic research in computer vision and deep learning
2. Users must comply with relevant laws and regulations, and must not use this project to bypass website security mechanisms
3. Any legal liability arising from the use of this project shall be borne by the user
4. Please do not use this project for any behavior that may harm others' interests

## ðŸ“ Project Structure

```
ider_CAPTCHA_Solver/
â”‚
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â””â”€â”€ config.yaml               # Project configuration
â”‚
â”œâ”€â”€ data/                          # Data directory
â”‚   â”œâ”€â”€ captchas/                  # Generated CAPTCHAs (354,024 images)
â”‚   â”‚   â””â”€â”€ Pic*.png              # Format: Pic{XXXX}_Bgx{X}Bgy{Y}_Sdx{X}Sdy{Y}_{hash}.png
â”‚   â”œâ”€â”€ raw_images/                # Raw images (2000 images)
â”‚   â”œâ”€â”€ real_captchas/             # Real CAPTCHA test set
â”‚   â”‚   â””â”€â”€ annotated/             # Annotated data (100 images)
â”‚   â”œâ”€â”€ annotations.json           # Training set annotations
â”‚   â”œâ”€â”€ test_annotations.json      # Test set annotations
â”‚   â”œâ”€â”€ generation_stats.json      # Generation statistics
â”‚   â””â”€â”€ dataset_split_stats.json   # Dataset split statistics
â”‚
â”œâ”€â”€ logs/                          # Log files
â”‚   â”œâ”€â”€ training_accuracy_curves_all.png    # Training accuracy curves
â”‚   â”œâ”€â”€ accuracy_comparison.png             # Test set vs real data comparison
â”‚   â”œâ”€â”€ training_analysis_report.txt        # Training analysis report
â”‚   â”œâ”€â”€ training_accuracy_results.csv       # Accuracy CSV data
â”‚   â”œâ”€â”€ training_accuracy_results.json      # Accuracy JSON data
â”‚   â”œâ”€â”€ evaluation_*.log                    # Evaluation logs
â”‚   â”œâ”€â”€ training_log.txt                    # Training log
â”‚   â””â”€â”€ benchmark_results_*.json            # Performance benchmark results
â”‚
â”œâ”€â”€ results/                       # Evaluation results
â”‚   â””â”€â”€ best_model_evaluation/     # Best model evaluation
â”‚       â”œâ”€â”€ test_dataset/          # Test set results
â”‚       â”‚   â”œâ”€â”€ evaluation_results.json     # Evaluation metrics
â”‚       â”‚   â””â”€â”€ visualizations/             # Visualizations (100 images)
â”‚       â”œâ”€â”€ real_captchas/         # Real CAPTCHA results
â”‚       â”‚   â”œâ”€â”€ evaluation_results.json     # Evaluation metrics
â”‚       â”‚   â””â”€â”€ visualizations/             # Visualizations (50 images)
â”‚       â””â”€â”€ summary_report.json    # Summary report
â”‚
â”œâ”€â”€ scripts/                       # Core scripts
â”‚   â”œâ”€â”€ annotation/                # Annotation tools
â”‚   â”‚   â”œâ”€â”€ annotate_captchas_matplotlib.py  # Matplotlib annotation UI
â”‚   â”‚   â””â”€â”€ annotate_captchas_web.py         # Web annotation UI
â”‚   â”‚
â”‚   â”œâ”€â”€ data_generation/           # Data generation scripts
â”‚   â”‚   â”œâ”€â”€ geometry_generator.py  # Geometry shape generator
â”‚   â”‚   â””â”€â”€ puzzle_background_generator.py   # Puzzle background generator
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                  # Training related
â”‚   â”‚   â”œâ”€â”€ train.py              # Main training script
â”‚   â”‚   â”œâ”€â”€ dataset.py            # PyTorch dataset class
â”‚   â”‚   â””â”€â”€ analyze_training.py   # Training analysis tool
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/                 # Inference related
â”‚   â”‚   â””â”€â”€ predict.py            # Prediction interface (CaptchaPredictor class)
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                # Evaluation scripts
â”‚   â”‚   â””â”€â”€ evaluate_model.py      # Comprehensive evaluation tool (multi-mode support)
â”‚   â”‚
â”‚   â”œâ”€â”€ download_images.py         # Pixabay image downloader
â”‚   â”œâ”€â”€ generate_captchas.py       # Batch CAPTCHA generator
â”‚   â””â”€â”€ split_dataset.py           # Dataset splitting script
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ checkpoints/               # Model weights
â”‚   â”‚   â”œâ”€â”€ 1.0.1/best_model.pth  # v1.0.1 model
â”‚   â”‚   â”œâ”€â”€ 1.0.2/best_model.pth  # v1.0.2 model (current)
â”‚   â”‚   â”œâ”€â”€ 1.0.3/best_model.pth  # v1.0.3 model (with anti-confusion)
â”‚   â”‚   â”œâ”€â”€ checkpoint_epoch_0001.pth ~ checkpoint_epoch_0020.pth  # Epoch checkpoints
â”‚   â”‚   â”œâ”€â”€ latest_checkpoint.pth  # Latest checkpoint
â”‚   â”‚   â”œâ”€â”€ training_log_*.txt     # Training logs
â”‚   â”‚   â””â”€â”€ logs/                  # TensorBoard logs
â”‚   â”‚       â””â”€â”€ events.out.tfevents.*
â”‚   â”‚
â”‚   â”œâ”€â”€ captcha_generator/         # CAPTCHA generation module
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ batch_generator.py    # Batch generator
â”‚   â”‚   â”œâ”€â”€ lighting_effects.py   # Lighting effects
â”‚   â”‚   â”œâ”€â”€ simple_puzzle_generator.py  # Puzzle generator
â”‚   â”‚   â””â”€â”€ slider_effects.py     # Slider effects
â”‚   â”‚
â”‚   â”œâ”€â”€ data_collection/           # Data collection module
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ pixabay_downloader.py # Pixabay downloader
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # Model definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ captcha_solver.py     # CaptchaSolver main model
â”‚   â”‚   â”œâ”€â”€ centernet_heads.py    # CenterNet detection heads
â”‚   â”‚   â”œâ”€â”€ losses.py             # Loss functions (Focal Loss + L1)
â”‚   â”‚   â””â”€â”€ resnet18_lite.py      # ResNet18-Lite backbone
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py             # Logging utilities
â”‚
â”œâ”€â”€ tests/                        # Test scripts
â”‚   â”œâ”€â”€ benchmark_inference.py     # Inference performance benchmark
â”‚   â”œâ”€â”€ merge_real_captchas.py     # Real CAPTCHA merge tool
â”‚   â”œâ”€â”€ test_all_puzzle_shapes.py  # All puzzle shapes test
â”‚   â”œâ”€â”€ test_captcha_generation.py # CAPTCHA generation test
â”‚   â”œâ”€â”€ test_darkness_levels.py    # Brightness level test
â”‚   â”œâ”€â”€ test_distance_error_visualization.py  # Distance error visualization
â”‚   â”œâ”€â”€ test_generate_captchas.py  # Generation function test
â”‚   â”œâ”€â”€ test_model_architecture.py # Model architecture test
â”‚   â”œâ”€â”€ test_real_captchas.py     # Real CAPTCHA test
â”‚   â””â”€â”€ test_slider_effects.py    # Slider effects test
â”‚
â”œâ”€â”€ outputs/                      # Test output files
â”‚   â””â”€â”€ *.png                     # Various test result images
â”‚
â”œâ”€â”€ api_example.py                # API usage examples
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ README.md                     # English documentation
â””â”€â”€ README_zh.md                  # Chinese documentation
```

## ðŸ”§ Tech Stack

- **Deep Learning Framework**: PyTorch 2.0+
- **Image Processing**: OpenCV, Pillow
- **Data Processing**: NumPy, Pandas
- **Visualization**: Matplotlib, Seaborn
- **Web Framework**: FastAPI
- **Others**: tqdm, requests, psutil

## ðŸ“ž Contact

For questions or suggestions, please submit an Issue or Pull Request.

---

<div align="center">
<i>This project is licensed under MIT License, for learning and research purposes only</i>
</div>