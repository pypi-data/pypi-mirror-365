import os
import getpass
from intro import show_intro
from langchain.chains.summarize.refine_prompts import prompt_template
from typing import Annotated, TypedDict, List, Optional
from langgraph.graph.message import add_messages
from langchain_core.messages import ToolMessage, HumanMessage
from langgraph.graph import StateGraph, START, END
from langchain_tavily import TavilySearch
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from openai import max_retries
from langchain.agents import create_react_agent, AgentExecutor
from langchain.tools import tool
from langchain_openai import OpenAIEmbeddings
import pandas as pd

"""
í™˜ê²½ë³€ìˆ˜ ì„¤ì •
"""
load_dotenv(override=True)

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
_set_env("TAVILY_API_KEY")

print(f"# OPENAI_API_KEY : {os.environ.get("OPENAI_API_KEY")[:10]}")
print(f"# TAVILY_API_KEY : {os.environ.get("TAVILY_API_KEY")[:10]}")


"""
ë³€ìˆ˜ ì •ì˜
"""
LLM_MODEL = "gpt-4o-mini"
DATA_FILE_PATH = "/imdb_top_1000.csv"
"""
ìƒíƒœ ì •ì˜
"""
class MyState(TypedDict):
    messages: List[dict]                 # ì „ì²´ ëŒ€í™” ê¸°ë¡
    ended: bool                          # ì¢…ë£Œ ì—¬ë¶€
    summary: List[str]                    # ì˜í™” ì¶”ì²œ ìš”ì•½
    recommendations: Optional[List[dict]] # ìµœì¢… ì¶”ì²œ ê²°ê³¼

"""
LLM ë° Embedding
"""
llm = ChatOpenAI(model=LLM_MODEL)
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

"""
Chatbot ë…¸ë“œ ì •ì˜
"""
# 1. ì±—ë´‡ tool
@tool
def chatbot_tool(state: MyState) -> MyState:
    """ì‚¬ìš©ìì˜ ì „ì²´ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©€í‹°í„´ ì˜í™” ëŒ€í™” ë° ìš”ì•½"""
    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    messages = state["messages"]
    # ë§ˆì§€ë§‰ ìœ ì € ë°œí™”
    last_user_msg = messages[-1]["content"] if messages else "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì‹ ê°€ìš”?"

    # ì±—ë´‡ ë‹µë³€ ìƒì„±
    convo = "\n".join([f"{m['role']}: {m['content']}" for m in messages])
    prompt = f"""
    ë‹¹ì‹ ì€ ì˜í™” ì¶”ì²œì„ ìœ„í•œ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
    ì§€ê¸ˆê¹Œì§€ ëŒ€í™”:
    {convo}

    ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë°œí™”: {last_user_msg}

    ì¹œê·¼í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ê³ ,
    ì˜í™” ì¶”ì²œì„ ìœ„í•œ ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì„¸ìš”.
    """
    bot_reply = llm.invoke(prompt).content.strip()
    messages.append({"role":"assistant","content":bot_reply})

    # ìœ ì € ë©”ì‹œì§€ê°€ 3ê°œ ì´ìƒì´ë©´ ìš”ì•½ ìƒì„±
    user_msgs = [m["content"] for m in messages if m["role"]=="user"]
    if len(user_msgs) >= 3:
        summary_prompt = f"""
        ë‹¤ìŒ ëŒ€í™”ë¥¼ ì˜í™” ì¶”ì²œì— í•„ìš”í•œ í•µì‹¬ ì •ë³´(ê°ì •, ì·¨í–¥) ìœ„ì£¼ë¡œ 1~2ë¬¸ì¥ ìš”ì•½í•˜ì„¸ìš”:
        {convo}
        """
        summary = llm.invoke(summary_prompt).content.strip()
        state["summary"] = [summary]
        state["ended"] = True

    state["messages"] = messages
    return state

# 2. ê°ì„± ë¶„ì„ tool
@tool
def movie_rec_tool(state: MyState) -> MyState:
    """ìš”ì•½ ê¸°ë°˜ìœ¼ë¡œ imdb_top_1000.csvì—ì„œ ì˜í™” 5ê°œì™€ ì¶”ì²œ ì‚¬ìœ  ìƒì„±"""
    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    # CSV ë¡œë“œ
    path = "/imdb_top_1000.csv"
    df = pd.read_csv(path)
    df = df[['Series_Title','Genre','Overview']].dropna().drop_duplicates()

    summary = state["summary"][0] if state["summary"] else "ì‚¬ìš©ì ìš”ì•½ ì—†ìŒ"

    # ì˜í™” í›„ë³´ 5ê°œë¥¼ ì„ ì •
    # dfì—ì„œ ëœë¤ ìƒ˜í”Œë¡œ í•„í„°ë§í•˜ì§€ ì•Šê³  LLMì´ ì„ íƒí•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì œê³µ
    sample_df = df.sample(30, random_state=42)  # LLM ì…ë ¥ ë¶€ë‹´ ì¤„ì´ê¸°
    movies_text = "\n".join([
        f"{row.Series_Title} ({row.Genre}): {row.Overview}"
        for _, row in sample_df.iterrows()
    ])

    prompt = f"""
    ì‚¬ìš©ìì˜ ì˜í™” ì·¨í–¥ ìš”ì•½:
    {summary}

    ì•„ë˜ëŠ” ì˜í™” í›„ë³´ ëª©ë¡ì…ë‹ˆë‹¤:
    {movies_text}

    ìœ„ í›„ë³´ ì¤‘ ì‚¬ìš©ì ìš”ì•½ì— ê°€ì¥ ì í•©í•œ ì˜í™” 5ê°œë¥¼ ê³ ë¥´ê³ ,
    ê° ì˜í™”ì— ëŒ€í•´ 1~2ë¬¸ì¥ìœ¼ë¡œ ì¶”ì²œ ì‚¬ìœ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    ë³´ê¸° ì¢‹ê²Œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
    [
        {{"title": "ì˜í™”ì œëª©", "reason": "ì¶”ì²œ ì‚¬ìœ "}},
        ...
    ]
    """
    resp = llm.invoke(prompt).content

    import json
    try:
        recommendations = json.loads(resp)
    except:
        # LLMì´ JSON í˜•ì‹ì´ ì•„ë‹ ê²½ìš° ëŒ€ë¹„
        recommendations = [{"title":"ì¶”ì²œ ì‹¤íŒ¨","reason":resp}]

    # ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    print("=== ğŸ¬ ìµœì¢… ì¶”ì²œ ì˜í™” 5ì„  ===")
    for rec in recommendations:
        print(f"- {rec['title']}: {rec['reason']}")

    state["recommendations"] = recommendations
    return state

tools = [chatbot_tool, movie_rec_tool]
agent = create_react_agent(llm, tools)
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)






def main():

    # ì•± ì´ˆê¸° UI
    show_intro()
    
    """
    LangGraph ìƒíƒœ ê·¸ë˜í”„ ì •ì˜
    """
    builder = StateGraph(MyState)
    builder.add_node("chatbot", chatbot)
    builder.add_edge(START, "chatbot")
    
    graph = builder.compile()
    # print(graph)



if __name__ == "__main__":
    # ì‹¤í–‰
    main() 