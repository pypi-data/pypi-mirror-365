# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins
import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = ['SinkKafkaArgs', 'SinkKafka']

@pulumi.input_type
class SinkKafkaArgs:
    def __init__(__self__, *,
                 from_: pulumi.Input['SinkKafkaFromArgs'],
                 kafka_connection: pulumi.Input['SinkKafkaKafkaConnectionArgs'],
                 topic: pulumi.Input[builtins.str],
                 cluster_name: Optional[pulumi.Input[builtins.str]] = None,
                 comment: Optional[pulumi.Input[builtins.str]] = None,
                 compression_type: Optional[pulumi.Input[builtins.str]] = None,
                 database_name: Optional[pulumi.Input[builtins.str]] = None,
                 envelope: Optional[pulumi.Input['SinkKafkaEnvelopeArgs']] = None,
                 format: Optional[pulumi.Input['SinkKafkaFormatArgs']] = None,
                 headers: Optional[pulumi.Input[builtins.str]] = None,
                 key_not_enforced: Optional[pulumi.Input[builtins.bool]] = None,
                 keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 ownership_role: Optional[pulumi.Input[builtins.str]] = None,
                 partition_by: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 schema_name: Optional[pulumi.Input[builtins.str]] = None,
                 snapshot: Optional[pulumi.Input[builtins.bool]] = None,
                 topic_config: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 topic_partition_count: Optional[pulumi.Input[builtins.int]] = None,
                 topic_replication_factor: Optional[pulumi.Input[builtins.int]] = None):
        """
        The set of arguments for constructing a SinkKafka resource.
        :param pulumi.Input['SinkKafkaFromArgs'] from_: The name of the source, table or materialized view you want to send to the sink.
        :param pulumi.Input['SinkKafkaKafkaConnectionArgs'] kafka_connection: The name of the Kafka connection to use in the sink.
        :param pulumi.Input[builtins.str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[builtins.str] cluster_name: The cluster to maintain this sink.
        :param pulumi.Input[builtins.str] comment: Comment on an object in the database.
        :param pulumi.Input[builtins.str] compression_type: The type of compression to apply to messages before they are sent to Kafka.
        :param pulumi.Input[builtins.str] database_name: The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        :param pulumi.Input['SinkKafkaEnvelopeArgs'] envelope: How to interpret records (e.g. Debezium, Upsert).
        :param pulumi.Input['SinkKafkaFormatArgs'] format: How to decode raw bytes from different formats into data structures it can understand at runtime.
        :param pulumi.Input[builtins.str] headers: The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        :param pulumi.Input[builtins.bool] key_not_enforced: Disable Materialize's validation of the key's uniqueness.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] keys: An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        :param pulumi.Input[builtins.str] name: The identifier for the sink.
        :param pulumi.Input[builtins.str] ownership_role: The owernship role of the object.
        :param pulumi.Input[builtins.str] partition_by: A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        :param pulumi.Input[builtins.str] region: The region to use for the resource connection. If not set, the default region is used.
        :param pulumi.Input[builtins.str] schema_name: The identifier for the sink schema in Materialize. Defaults to `public`.
        :param pulumi.Input[builtins.bool] snapshot: Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] topic_config: Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_partition_count: The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_replication_factor: The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        pulumi.set(__self__, "from_", from_)
        pulumi.set(__self__, "kafka_connection", kafka_connection)
        pulumi.set(__self__, "topic", topic)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if database_name is not None:
            pulumi.set(__self__, "database_name", database_name)
        if envelope is not None:
            pulumi.set(__self__, "envelope", envelope)
        if format is not None:
            pulumi.set(__self__, "format", format)
        if headers is not None:
            pulumi.set(__self__, "headers", headers)
        if key_not_enforced is not None:
            pulumi.set(__self__, "key_not_enforced", key_not_enforced)
        if keys is not None:
            pulumi.set(__self__, "keys", keys)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if ownership_role is not None:
            pulumi.set(__self__, "ownership_role", ownership_role)
        if partition_by is not None:
            pulumi.set(__self__, "partition_by", partition_by)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if snapshot is not None:
            pulumi.set(__self__, "snapshot", snapshot)
        if topic_config is not None:
            pulumi.set(__self__, "topic_config", topic_config)
        if topic_partition_count is not None:
            pulumi.set(__self__, "topic_partition_count", topic_partition_count)
        if topic_replication_factor is not None:
            pulumi.set(__self__, "topic_replication_factor", topic_replication_factor)

    @property
    @pulumi.getter(name="from")
    def from_(self) -> pulumi.Input['SinkKafkaFromArgs']:
        """
        The name of the source, table or materialized view you want to send to the sink.
        """
        return pulumi.get(self, "from_")

    @from_.setter
    def from_(self, value: pulumi.Input['SinkKafkaFromArgs']):
        pulumi.set(self, "from_", value)

    @property
    @pulumi.getter(name="kafkaConnection")
    def kafka_connection(self) -> pulumi.Input['SinkKafkaKafkaConnectionArgs']:
        """
        The name of the Kafka connection to use in the sink.
        """
        return pulumi.get(self, "kafka_connection")

    @kafka_connection.setter
    def kafka_connection(self, value: pulumi.Input['SinkKafkaKafkaConnectionArgs']):
        pulumi.set(self, "kafka_connection", value)

    @property
    @pulumi.getter
    def topic(self) -> pulumi.Input[builtins.str]:
        """
        The Kafka topic you want to subscribe to.
        """
        return pulumi.get(self, "topic")

    @topic.setter
    def topic(self, value: pulumi.Input[builtins.str]):
        pulumi.set(self, "topic", value)

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The cluster to maintain this sink.
        """
        return pulumi.get(self, "cluster_name")

    @cluster_name.setter
    def cluster_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_name", value)

    @property
    @pulumi.getter
    def comment(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Comment on an object in the database.
        """
        return pulumi.get(self, "comment")

    @comment.setter
    def comment(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "comment", value)

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The type of compression to apply to messages before they are sent to Kafka.
        """
        return pulumi.get(self, "compression_type")

    @compression_type.setter
    def compression_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "compression_type", value)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        """
        return pulumi.get(self, "database_name")

    @database_name.setter
    def database_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "database_name", value)

    @property
    @pulumi.getter
    def envelope(self) -> Optional[pulumi.Input['SinkKafkaEnvelopeArgs']]:
        """
        How to interpret records (e.g. Debezium, Upsert).
        """
        return pulumi.get(self, "envelope")

    @envelope.setter
    def envelope(self, value: Optional[pulumi.Input['SinkKafkaEnvelopeArgs']]):
        pulumi.set(self, "envelope", value)

    @property
    @pulumi.getter
    def format(self) -> Optional[pulumi.Input['SinkKafkaFormatArgs']]:
        """
        How to decode raw bytes from different formats into data structures it can understand at runtime.
        """
        return pulumi.get(self, "format")

    @format.setter
    def format(self, value: Optional[pulumi.Input['SinkKafkaFormatArgs']]):
        pulumi.set(self, "format", value)

    @property
    @pulumi.getter
    def headers(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        """
        return pulumi.get(self, "headers")

    @headers.setter
    def headers(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "headers", value)

    @property
    @pulumi.getter(name="keyNotEnforced")
    def key_not_enforced(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Disable Materialize's validation of the key's uniqueness.
        """
        return pulumi.get(self, "key_not_enforced")

    @key_not_enforced.setter
    def key_not_enforced(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "key_not_enforced", value)

    @property
    @pulumi.getter
    def keys(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        """
        return pulumi.get(self, "keys")

    @keys.setter
    def keys(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "keys", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The identifier for the sink.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="ownershipRole")
    def ownership_role(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The owernship role of the object.
        """
        return pulumi.get(self, "ownership_role")

    @ownership_role.setter
    def ownership_role(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "ownership_role", value)

    @property
    @pulumi.getter(name="partitionBy")
    def partition_by(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        """
        return pulumi.get(self, "partition_by")

    @partition_by.setter
    def partition_by(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "partition_by", value)

    @property
    @pulumi.getter
    def region(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The region to use for the resource connection. If not set, the default region is used.
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "region", value)

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The identifier for the sink schema in Materialize. Defaults to `public`.
        """
        return pulumi.get(self, "schema_name")

    @schema_name.setter
    def schema_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "schema_name", value)

    @property
    @pulumi.getter
    def snapshot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        """
        return pulumi.get(self, "snapshot")

    @snapshot.setter
    def snapshot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "snapshot", value)

    @property
    @pulumi.getter(name="topicConfig")
    def topic_config(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_config")

    @topic_config.setter
    def topic_config(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "topic_config", value)

    @property
    @pulumi.getter(name="topicPartitionCount")
    def topic_partition_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_partition_count")

    @topic_partition_count.setter
    def topic_partition_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "topic_partition_count", value)

    @property
    @pulumi.getter(name="topicReplicationFactor")
    def topic_replication_factor(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_replication_factor")

    @topic_replication_factor.setter
    def topic_replication_factor(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "topic_replication_factor", value)


@pulumi.input_type
class _SinkKafkaState:
    def __init__(__self__, *,
                 cluster_name: Optional[pulumi.Input[builtins.str]] = None,
                 comment: Optional[pulumi.Input[builtins.str]] = None,
                 compression_type: Optional[pulumi.Input[builtins.str]] = None,
                 database_name: Optional[pulumi.Input[builtins.str]] = None,
                 envelope: Optional[pulumi.Input['SinkKafkaEnvelopeArgs']] = None,
                 format: Optional[pulumi.Input['SinkKafkaFormatArgs']] = None,
                 from_: Optional[pulumi.Input['SinkKafkaFromArgs']] = None,
                 headers: Optional[pulumi.Input[builtins.str]] = None,
                 kafka_connection: Optional[pulumi.Input['SinkKafkaKafkaConnectionArgs']] = None,
                 key_not_enforced: Optional[pulumi.Input[builtins.bool]] = None,
                 keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 ownership_role: Optional[pulumi.Input[builtins.str]] = None,
                 partition_by: Optional[pulumi.Input[builtins.str]] = None,
                 qualified_sql_name: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 schema_name: Optional[pulumi.Input[builtins.str]] = None,
                 size: Optional[pulumi.Input[builtins.str]] = None,
                 snapshot: Optional[pulumi.Input[builtins.bool]] = None,
                 topic: Optional[pulumi.Input[builtins.str]] = None,
                 topic_config: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 topic_partition_count: Optional[pulumi.Input[builtins.int]] = None,
                 topic_replication_factor: Optional[pulumi.Input[builtins.int]] = None):
        """
        Input properties used for looking up and filtering SinkKafka resources.
        :param pulumi.Input[builtins.str] cluster_name: The cluster to maintain this sink.
        :param pulumi.Input[builtins.str] comment: Comment on an object in the database.
        :param pulumi.Input[builtins.str] compression_type: The type of compression to apply to messages before they are sent to Kafka.
        :param pulumi.Input[builtins.str] database_name: The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        :param pulumi.Input['SinkKafkaEnvelopeArgs'] envelope: How to interpret records (e.g. Debezium, Upsert).
        :param pulumi.Input['SinkKafkaFormatArgs'] format: How to decode raw bytes from different formats into data structures it can understand at runtime.
        :param pulumi.Input['SinkKafkaFromArgs'] from_: The name of the source, table or materialized view you want to send to the sink.
        :param pulumi.Input[builtins.str] headers: The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        :param pulumi.Input['SinkKafkaKafkaConnectionArgs'] kafka_connection: The name of the Kafka connection to use in the sink.
        :param pulumi.Input[builtins.bool] key_not_enforced: Disable Materialize's validation of the key's uniqueness.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] keys: An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        :param pulumi.Input[builtins.str] name: The identifier for the sink.
        :param pulumi.Input[builtins.str] ownership_role: The owernship role of the object.
        :param pulumi.Input[builtins.str] partition_by: A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        :param pulumi.Input[builtins.str] qualified_sql_name: The fully qualified name of the sink.
        :param pulumi.Input[builtins.str] region: The region to use for the resource connection. If not set, the default region is used.
        :param pulumi.Input[builtins.str] schema_name: The identifier for the sink schema in Materialize. Defaults to `public`.
        :param pulumi.Input[builtins.str] size: The size of the cluster maintaining this sink.
        :param pulumi.Input[builtins.bool] snapshot: Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        :param pulumi.Input[builtins.str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] topic_config: Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_partition_count: The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_replication_factor: The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if database_name is not None:
            pulumi.set(__self__, "database_name", database_name)
        if envelope is not None:
            pulumi.set(__self__, "envelope", envelope)
        if format is not None:
            pulumi.set(__self__, "format", format)
        if from_ is not None:
            pulumi.set(__self__, "from_", from_)
        if headers is not None:
            pulumi.set(__self__, "headers", headers)
        if kafka_connection is not None:
            pulumi.set(__self__, "kafka_connection", kafka_connection)
        if key_not_enforced is not None:
            pulumi.set(__self__, "key_not_enforced", key_not_enforced)
        if keys is not None:
            pulumi.set(__self__, "keys", keys)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if ownership_role is not None:
            pulumi.set(__self__, "ownership_role", ownership_role)
        if partition_by is not None:
            pulumi.set(__self__, "partition_by", partition_by)
        if qualified_sql_name is not None:
            pulumi.set(__self__, "qualified_sql_name", qualified_sql_name)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if size is not None:
            pulumi.set(__self__, "size", size)
        if snapshot is not None:
            pulumi.set(__self__, "snapshot", snapshot)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)
        if topic_config is not None:
            pulumi.set(__self__, "topic_config", topic_config)
        if topic_partition_count is not None:
            pulumi.set(__self__, "topic_partition_count", topic_partition_count)
        if topic_replication_factor is not None:
            pulumi.set(__self__, "topic_replication_factor", topic_replication_factor)

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The cluster to maintain this sink.
        """
        return pulumi.get(self, "cluster_name")

    @cluster_name.setter
    def cluster_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "cluster_name", value)

    @property
    @pulumi.getter
    def comment(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        Comment on an object in the database.
        """
        return pulumi.get(self, "comment")

    @comment.setter
    def comment(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "comment", value)

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The type of compression to apply to messages before they are sent to Kafka.
        """
        return pulumi.get(self, "compression_type")

    @compression_type.setter
    def compression_type(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "compression_type", value)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        """
        return pulumi.get(self, "database_name")

    @database_name.setter
    def database_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "database_name", value)

    @property
    @pulumi.getter
    def envelope(self) -> Optional[pulumi.Input['SinkKafkaEnvelopeArgs']]:
        """
        How to interpret records (e.g. Debezium, Upsert).
        """
        return pulumi.get(self, "envelope")

    @envelope.setter
    def envelope(self, value: Optional[pulumi.Input['SinkKafkaEnvelopeArgs']]):
        pulumi.set(self, "envelope", value)

    @property
    @pulumi.getter
    def format(self) -> Optional[pulumi.Input['SinkKafkaFormatArgs']]:
        """
        How to decode raw bytes from different formats into data structures it can understand at runtime.
        """
        return pulumi.get(self, "format")

    @format.setter
    def format(self, value: Optional[pulumi.Input['SinkKafkaFormatArgs']]):
        pulumi.set(self, "format", value)

    @property
    @pulumi.getter(name="from")
    def from_(self) -> Optional[pulumi.Input['SinkKafkaFromArgs']]:
        """
        The name of the source, table or materialized view you want to send to the sink.
        """
        return pulumi.get(self, "from_")

    @from_.setter
    def from_(self, value: Optional[pulumi.Input['SinkKafkaFromArgs']]):
        pulumi.set(self, "from_", value)

    @property
    @pulumi.getter
    def headers(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        """
        return pulumi.get(self, "headers")

    @headers.setter
    def headers(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "headers", value)

    @property
    @pulumi.getter(name="kafkaConnection")
    def kafka_connection(self) -> Optional[pulumi.Input['SinkKafkaKafkaConnectionArgs']]:
        """
        The name of the Kafka connection to use in the sink.
        """
        return pulumi.get(self, "kafka_connection")

    @kafka_connection.setter
    def kafka_connection(self, value: Optional[pulumi.Input['SinkKafkaKafkaConnectionArgs']]):
        pulumi.set(self, "kafka_connection", value)

    @property
    @pulumi.getter(name="keyNotEnforced")
    def key_not_enforced(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Disable Materialize's validation of the key's uniqueness.
        """
        return pulumi.get(self, "key_not_enforced")

    @key_not_enforced.setter
    def key_not_enforced(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "key_not_enforced", value)

    @property
    @pulumi.getter
    def keys(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]:
        """
        An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        """
        return pulumi.get(self, "keys")

    @keys.setter
    def keys(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "keys", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The identifier for the sink.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="ownershipRole")
    def ownership_role(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The owernship role of the object.
        """
        return pulumi.get(self, "ownership_role")

    @ownership_role.setter
    def ownership_role(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "ownership_role", value)

    @property
    @pulumi.getter(name="partitionBy")
    def partition_by(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        """
        return pulumi.get(self, "partition_by")

    @partition_by.setter
    def partition_by(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "partition_by", value)

    @property
    @pulumi.getter(name="qualifiedSqlName")
    def qualified_sql_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The fully qualified name of the sink.
        """
        return pulumi.get(self, "qualified_sql_name")

    @qualified_sql_name.setter
    def qualified_sql_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "qualified_sql_name", value)

    @property
    @pulumi.getter
    def region(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The region to use for the resource connection. If not set, the default region is used.
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "region", value)

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The identifier for the sink schema in Materialize. Defaults to `public`.
        """
        return pulumi.get(self, "schema_name")

    @schema_name.setter
    def schema_name(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "schema_name", value)

    @property
    @pulumi.getter
    def size(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The size of the cluster maintaining this sink.
        """
        return pulumi.get(self, "size")

    @size.setter
    def size(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "size", value)

    @property
    @pulumi.getter
    def snapshot(self) -> Optional[pulumi.Input[builtins.bool]]:
        """
        Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        """
        return pulumi.get(self, "snapshot")

    @snapshot.setter
    def snapshot(self, value: Optional[pulumi.Input[builtins.bool]]):
        pulumi.set(self, "snapshot", value)

    @property
    @pulumi.getter
    def topic(self) -> Optional[pulumi.Input[builtins.str]]:
        """
        The Kafka topic you want to subscribe to.
        """
        return pulumi.get(self, "topic")

    @topic.setter
    def topic(self, value: Optional[pulumi.Input[builtins.str]]):
        pulumi.set(self, "topic", value)

    @property
    @pulumi.getter(name="topicConfig")
    def topic_config(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]:
        """
        Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_config")

    @topic_config.setter
    def topic_config(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]]):
        pulumi.set(self, "topic_config", value)

    @property
    @pulumi.getter(name="topicPartitionCount")
    def topic_partition_count(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_partition_count")

    @topic_partition_count.setter
    def topic_partition_count(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "topic_partition_count", value)

    @property
    @pulumi.getter(name="topicReplicationFactor")
    def topic_replication_factor(self) -> Optional[pulumi.Input[builtins.int]]:
        """
        The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_replication_factor")

    @topic_replication_factor.setter
    def topic_replication_factor(self, value: Optional[pulumi.Input[builtins.int]]):
        pulumi.set(self, "topic_replication_factor", value)


@pulumi.type_token("materialize:index/sinkKafka:SinkKafka")
class SinkKafka(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 cluster_name: Optional[pulumi.Input[builtins.str]] = None,
                 comment: Optional[pulumi.Input[builtins.str]] = None,
                 compression_type: Optional[pulumi.Input[builtins.str]] = None,
                 database_name: Optional[pulumi.Input[builtins.str]] = None,
                 envelope: Optional[pulumi.Input[Union['SinkKafkaEnvelopeArgs', 'SinkKafkaEnvelopeArgsDict']]] = None,
                 format: Optional[pulumi.Input[Union['SinkKafkaFormatArgs', 'SinkKafkaFormatArgsDict']]] = None,
                 from_: Optional[pulumi.Input[Union['SinkKafkaFromArgs', 'SinkKafkaFromArgsDict']]] = None,
                 headers: Optional[pulumi.Input[builtins.str]] = None,
                 kafka_connection: Optional[pulumi.Input[Union['SinkKafkaKafkaConnectionArgs', 'SinkKafkaKafkaConnectionArgsDict']]] = None,
                 key_not_enforced: Optional[pulumi.Input[builtins.bool]] = None,
                 keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 ownership_role: Optional[pulumi.Input[builtins.str]] = None,
                 partition_by: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 schema_name: Optional[pulumi.Input[builtins.str]] = None,
                 snapshot: Optional[pulumi.Input[builtins.bool]] = None,
                 topic: Optional[pulumi.Input[builtins.str]] = None,
                 topic_config: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 topic_partition_count: Optional[pulumi.Input[builtins.int]] = None,
                 topic_replication_factor: Optional[pulumi.Input[builtins.int]] = None,
                 __props__=None):
        """
        A Kafka sink establishes a link to a Kafka cluster that you want Materialize to write data to.

        ## Example Usage

        ```python
        import pulumi
        import pulumi_materialize as materialize

        example_sink_kafka = materialize.SinkKafka("exampleSinkKafka",
            cluster_name="quickstart",
            envelope={
                "upsert": True,
            },
            format={
                "avro": {
                    "schema_registry_connection": {
                        "database_name": "database",
                        "name": "csr_connection",
                        "schema_name": "schema",
                    },
                },
            },
            from_={
                "name": "table",
            },
            kafka_connection={
                "name": "kafka_connection",
            },
            schema_name="schema",
            topic="test_avro_topic")
        ```

        ## Import

        The `pulumi import` command can be used, for example:

        Sinks can be imported using the sink id:

        ```sh
        $ pulumi import materialize:index/sinkKafka:SinkKafka example_sink_kafka <region>:<sink_id>
        ```

        Sink id and information be found in the `mz_catalog.mz_sinks` table

        The region is the region where the database is located (e.g. aws/us-east-1)

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[builtins.str] cluster_name: The cluster to maintain this sink.
        :param pulumi.Input[builtins.str] comment: Comment on an object in the database.
        :param pulumi.Input[builtins.str] compression_type: The type of compression to apply to messages before they are sent to Kafka.
        :param pulumi.Input[builtins.str] database_name: The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        :param pulumi.Input[Union['SinkKafkaEnvelopeArgs', 'SinkKafkaEnvelopeArgsDict']] envelope: How to interpret records (e.g. Debezium, Upsert).
        :param pulumi.Input[Union['SinkKafkaFormatArgs', 'SinkKafkaFormatArgsDict']] format: How to decode raw bytes from different formats into data structures it can understand at runtime.
        :param pulumi.Input[Union['SinkKafkaFromArgs', 'SinkKafkaFromArgsDict']] from_: The name of the source, table or materialized view you want to send to the sink.
        :param pulumi.Input[builtins.str] headers: The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        :param pulumi.Input[Union['SinkKafkaKafkaConnectionArgs', 'SinkKafkaKafkaConnectionArgsDict']] kafka_connection: The name of the Kafka connection to use in the sink.
        :param pulumi.Input[builtins.bool] key_not_enforced: Disable Materialize's validation of the key's uniqueness.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] keys: An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        :param pulumi.Input[builtins.str] name: The identifier for the sink.
        :param pulumi.Input[builtins.str] ownership_role: The owernship role of the object.
        :param pulumi.Input[builtins.str] partition_by: A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        :param pulumi.Input[builtins.str] region: The region to use for the resource connection. If not set, the default region is used.
        :param pulumi.Input[builtins.str] schema_name: The identifier for the sink schema in Materialize. Defaults to `public`.
        :param pulumi.Input[builtins.bool] snapshot: Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        :param pulumi.Input[builtins.str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] topic_config: Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_partition_count: The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_replication_factor: The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: SinkKafkaArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        A Kafka sink establishes a link to a Kafka cluster that you want Materialize to write data to.

        ## Example Usage

        ```python
        import pulumi
        import pulumi_materialize as materialize

        example_sink_kafka = materialize.SinkKafka("exampleSinkKafka",
            cluster_name="quickstart",
            envelope={
                "upsert": True,
            },
            format={
                "avro": {
                    "schema_registry_connection": {
                        "database_name": "database",
                        "name": "csr_connection",
                        "schema_name": "schema",
                    },
                },
            },
            from_={
                "name": "table",
            },
            kafka_connection={
                "name": "kafka_connection",
            },
            schema_name="schema",
            topic="test_avro_topic")
        ```

        ## Import

        The `pulumi import` command can be used, for example:

        Sinks can be imported using the sink id:

        ```sh
        $ pulumi import materialize:index/sinkKafka:SinkKafka example_sink_kafka <region>:<sink_id>
        ```

        Sink id and information be found in the `mz_catalog.mz_sinks` table

        The region is the region where the database is located (e.g. aws/us-east-1)

        :param str resource_name: The name of the resource.
        :param SinkKafkaArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(SinkKafkaArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 cluster_name: Optional[pulumi.Input[builtins.str]] = None,
                 comment: Optional[pulumi.Input[builtins.str]] = None,
                 compression_type: Optional[pulumi.Input[builtins.str]] = None,
                 database_name: Optional[pulumi.Input[builtins.str]] = None,
                 envelope: Optional[pulumi.Input[Union['SinkKafkaEnvelopeArgs', 'SinkKafkaEnvelopeArgsDict']]] = None,
                 format: Optional[pulumi.Input[Union['SinkKafkaFormatArgs', 'SinkKafkaFormatArgsDict']]] = None,
                 from_: Optional[pulumi.Input[Union['SinkKafkaFromArgs', 'SinkKafkaFromArgsDict']]] = None,
                 headers: Optional[pulumi.Input[builtins.str]] = None,
                 kafka_connection: Optional[pulumi.Input[Union['SinkKafkaKafkaConnectionArgs', 'SinkKafkaKafkaConnectionArgsDict']]] = None,
                 key_not_enforced: Optional[pulumi.Input[builtins.bool]] = None,
                 keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
                 name: Optional[pulumi.Input[builtins.str]] = None,
                 ownership_role: Optional[pulumi.Input[builtins.str]] = None,
                 partition_by: Optional[pulumi.Input[builtins.str]] = None,
                 region: Optional[pulumi.Input[builtins.str]] = None,
                 schema_name: Optional[pulumi.Input[builtins.str]] = None,
                 snapshot: Optional[pulumi.Input[builtins.bool]] = None,
                 topic: Optional[pulumi.Input[builtins.str]] = None,
                 topic_config: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
                 topic_partition_count: Optional[pulumi.Input[builtins.int]] = None,
                 topic_replication_factor: Optional[pulumi.Input[builtins.int]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = SinkKafkaArgs.__new__(SinkKafkaArgs)

            __props__.__dict__["cluster_name"] = cluster_name
            __props__.__dict__["comment"] = comment
            __props__.__dict__["compression_type"] = compression_type
            __props__.__dict__["database_name"] = database_name
            __props__.__dict__["envelope"] = envelope
            __props__.__dict__["format"] = format
            if from_ is None and not opts.urn:
                raise TypeError("Missing required property 'from_'")
            __props__.__dict__["from_"] = from_
            __props__.__dict__["headers"] = headers
            if kafka_connection is None and not opts.urn:
                raise TypeError("Missing required property 'kafka_connection'")
            __props__.__dict__["kafka_connection"] = kafka_connection
            __props__.__dict__["key_not_enforced"] = key_not_enforced
            __props__.__dict__["keys"] = keys
            __props__.__dict__["name"] = name
            __props__.__dict__["ownership_role"] = ownership_role
            __props__.__dict__["partition_by"] = partition_by
            __props__.__dict__["region"] = region
            __props__.__dict__["schema_name"] = schema_name
            __props__.__dict__["snapshot"] = snapshot
            if topic is None and not opts.urn:
                raise TypeError("Missing required property 'topic'")
            __props__.__dict__["topic"] = topic
            __props__.__dict__["topic_config"] = topic_config
            __props__.__dict__["topic_partition_count"] = topic_partition_count
            __props__.__dict__["topic_replication_factor"] = topic_replication_factor
            __props__.__dict__["qualified_sql_name"] = None
            __props__.__dict__["size"] = None
        super(SinkKafka, __self__).__init__(
            'materialize:index/sinkKafka:SinkKafka',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            cluster_name: Optional[pulumi.Input[builtins.str]] = None,
            comment: Optional[pulumi.Input[builtins.str]] = None,
            compression_type: Optional[pulumi.Input[builtins.str]] = None,
            database_name: Optional[pulumi.Input[builtins.str]] = None,
            envelope: Optional[pulumi.Input[Union['SinkKafkaEnvelopeArgs', 'SinkKafkaEnvelopeArgsDict']]] = None,
            format: Optional[pulumi.Input[Union['SinkKafkaFormatArgs', 'SinkKafkaFormatArgsDict']]] = None,
            from_: Optional[pulumi.Input[Union['SinkKafkaFromArgs', 'SinkKafkaFromArgsDict']]] = None,
            headers: Optional[pulumi.Input[builtins.str]] = None,
            kafka_connection: Optional[pulumi.Input[Union['SinkKafkaKafkaConnectionArgs', 'SinkKafkaKafkaConnectionArgsDict']]] = None,
            key_not_enforced: Optional[pulumi.Input[builtins.bool]] = None,
            keys: Optional[pulumi.Input[Sequence[pulumi.Input[builtins.str]]]] = None,
            name: Optional[pulumi.Input[builtins.str]] = None,
            ownership_role: Optional[pulumi.Input[builtins.str]] = None,
            partition_by: Optional[pulumi.Input[builtins.str]] = None,
            qualified_sql_name: Optional[pulumi.Input[builtins.str]] = None,
            region: Optional[pulumi.Input[builtins.str]] = None,
            schema_name: Optional[pulumi.Input[builtins.str]] = None,
            size: Optional[pulumi.Input[builtins.str]] = None,
            snapshot: Optional[pulumi.Input[builtins.bool]] = None,
            topic: Optional[pulumi.Input[builtins.str]] = None,
            topic_config: Optional[pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]]] = None,
            topic_partition_count: Optional[pulumi.Input[builtins.int]] = None,
            topic_replication_factor: Optional[pulumi.Input[builtins.int]] = None) -> 'SinkKafka':
        """
        Get an existing SinkKafka resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[builtins.str] cluster_name: The cluster to maintain this sink.
        :param pulumi.Input[builtins.str] comment: Comment on an object in the database.
        :param pulumi.Input[builtins.str] compression_type: The type of compression to apply to messages before they are sent to Kafka.
        :param pulumi.Input[builtins.str] database_name: The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        :param pulumi.Input[Union['SinkKafkaEnvelopeArgs', 'SinkKafkaEnvelopeArgsDict']] envelope: How to interpret records (e.g. Debezium, Upsert).
        :param pulumi.Input[Union['SinkKafkaFormatArgs', 'SinkKafkaFormatArgsDict']] format: How to decode raw bytes from different formats into data structures it can understand at runtime.
        :param pulumi.Input[Union['SinkKafkaFromArgs', 'SinkKafkaFromArgsDict']] from_: The name of the source, table or materialized view you want to send to the sink.
        :param pulumi.Input[builtins.str] headers: The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        :param pulumi.Input[Union['SinkKafkaKafkaConnectionArgs', 'SinkKafkaKafkaConnectionArgsDict']] kafka_connection: The name of the Kafka connection to use in the sink.
        :param pulumi.Input[builtins.bool] key_not_enforced: Disable Materialize's validation of the key's uniqueness.
        :param pulumi.Input[Sequence[pulumi.Input[builtins.str]]] keys: An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        :param pulumi.Input[builtins.str] name: The identifier for the sink.
        :param pulumi.Input[builtins.str] ownership_role: The owernship role of the object.
        :param pulumi.Input[builtins.str] partition_by: A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        :param pulumi.Input[builtins.str] qualified_sql_name: The fully qualified name of the sink.
        :param pulumi.Input[builtins.str] region: The region to use for the resource connection. If not set, the default region is used.
        :param pulumi.Input[builtins.str] schema_name: The identifier for the sink schema in Materialize. Defaults to `public`.
        :param pulumi.Input[builtins.str] size: The size of the cluster maintaining this sink.
        :param pulumi.Input[builtins.bool] snapshot: Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        :param pulumi.Input[builtins.str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[Mapping[str, pulumi.Input[builtins.str]]] topic_config: Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_partition_count: The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        :param pulumi.Input[builtins.int] topic_replication_factor: The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _SinkKafkaState.__new__(_SinkKafkaState)

        __props__.__dict__["cluster_name"] = cluster_name
        __props__.__dict__["comment"] = comment
        __props__.__dict__["compression_type"] = compression_type
        __props__.__dict__["database_name"] = database_name
        __props__.__dict__["envelope"] = envelope
        __props__.__dict__["format"] = format
        __props__.__dict__["from_"] = from_
        __props__.__dict__["headers"] = headers
        __props__.__dict__["kafka_connection"] = kafka_connection
        __props__.__dict__["key_not_enforced"] = key_not_enforced
        __props__.__dict__["keys"] = keys
        __props__.__dict__["name"] = name
        __props__.__dict__["ownership_role"] = ownership_role
        __props__.__dict__["partition_by"] = partition_by
        __props__.__dict__["qualified_sql_name"] = qualified_sql_name
        __props__.__dict__["region"] = region
        __props__.__dict__["schema_name"] = schema_name
        __props__.__dict__["size"] = size
        __props__.__dict__["snapshot"] = snapshot
        __props__.__dict__["topic"] = topic
        __props__.__dict__["topic_config"] = topic_config
        __props__.__dict__["topic_partition_count"] = topic_partition_count
        __props__.__dict__["topic_replication_factor"] = topic_replication_factor
        return SinkKafka(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> pulumi.Output[builtins.str]:
        """
        The cluster to maintain this sink.
        """
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter
    def comment(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        Comment on an object in the database.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The type of compression to apply to messages before they are sent to Kafka.
        """
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The identifier for the sink database in Materialize. Defaults to `MZ_DATABASE` environment variable if set or `materialize` if environment variable is not set.
        """
        return pulumi.get(self, "database_name")

    @property
    @pulumi.getter
    def envelope(self) -> pulumi.Output[Optional['outputs.SinkKafkaEnvelope']]:
        """
        How to interpret records (e.g. Debezium, Upsert).
        """
        return pulumi.get(self, "envelope")

    @property
    @pulumi.getter
    def format(self) -> pulumi.Output[Optional['outputs.SinkKafkaFormat']]:
        """
        How to decode raw bytes from different formats into data structures it can understand at runtime.
        """
        return pulumi.get(self, "format")

    @property
    @pulumi.getter(name="from")
    def from_(self) -> pulumi.Output['outputs.SinkKafkaFrom']:
        """
        The name of the source, table or materialized view you want to send to the sink.
        """
        return pulumi.get(self, "from_")

    @property
    @pulumi.getter
    def headers(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The name of a column containing additional headers to add to each message emitted by the sink. The column must be of type map[text => text] or map[text => bytea].
        """
        return pulumi.get(self, "headers")

    @property
    @pulumi.getter(name="kafkaConnection")
    def kafka_connection(self) -> pulumi.Output['outputs.SinkKafkaKafkaConnection']:
        """
        The name of the Kafka connection to use in the sink.
        """
        return pulumi.get(self, "kafka_connection")

    @property
    @pulumi.getter(name="keyNotEnforced")
    def key_not_enforced(self) -> pulumi.Output[Optional[builtins.bool]]:
        """
        Disable Materialize's validation of the key's uniqueness.
        """
        return pulumi.get(self, "key_not_enforced")

    @property
    @pulumi.getter
    def keys(self) -> pulumi.Output[Optional[Sequence[builtins.str]]]:
        """
        An optional list of columns to use for the Kafka key. If unspecified, the Kafka key is left unset.
        """
        return pulumi.get(self, "keys")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[builtins.str]:
        """
        The identifier for the sink.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="ownershipRole")
    def ownership_role(self) -> pulumi.Output[builtins.str]:
        """
        The owernship role of the object.
        """
        return pulumi.get(self, "ownership_role")

    @property
    @pulumi.getter(name="partitionBy")
    def partition_by(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        A SQL expression used to partition the data in the Kafka sink. Can only be used with `ENVELOPE UPSERT`.
        """
        return pulumi.get(self, "partition_by")

    @property
    @pulumi.getter(name="qualifiedSqlName")
    def qualified_sql_name(self) -> pulumi.Output[builtins.str]:
        """
        The fully qualified name of the sink.
        """
        return pulumi.get(self, "qualified_sql_name")

    @property
    @pulumi.getter
    def region(self) -> pulumi.Output[builtins.str]:
        """
        The region to use for the resource connection. If not set, the default region is used.
        """
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> pulumi.Output[Optional[builtins.str]]:
        """
        The identifier for the sink schema in Materialize. Defaults to `public`.
        """
        return pulumi.get(self, "schema_name")

    @property
    @pulumi.getter
    def size(self) -> pulumi.Output[builtins.str]:
        """
        The size of the cluster maintaining this sink.
        """
        return pulumi.get(self, "size")

    @property
    @pulumi.getter
    def snapshot(self) -> pulumi.Output[Optional[builtins.bool]]:
        """
        Whether to emit the consolidated results of the query before the sink was created at the start of the sink.
        """
        return pulumi.get(self, "snapshot")

    @property
    @pulumi.getter
    def topic(self) -> pulumi.Output[builtins.str]:
        """
        The Kafka topic you want to subscribe to.
        """
        return pulumi.get(self, "topic")

    @property
    @pulumi.getter(name="topicConfig")
    def topic_config(self) -> pulumi.Output[Optional[Mapping[str, builtins.str]]]:
        """
        Any topic-level configs to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_config")

    @property
    @pulumi.getter(name="topicPartitionCount")
    def topic_partition_count(self) -> pulumi.Output[Optional[builtins.int]]:
        """
        The partition count to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_partition_count")

    @property
    @pulumi.getter(name="topicReplicationFactor")
    def topic_replication_factor(self) -> pulumi.Output[Optional[builtins.int]]:
        """
        The replication factor to use when creating the Kafka topic (if the Kafka topic does not already exist).
        """
        return pulumi.get(self, "topic_replication_factor")

