#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´æµ‹è¯•å¥—ä»¶è¿è¡Œå™¨
===============

è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
"""

import unittest
import sys
import os
import logging
import time
from io import StringIO

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))

# å¯¼å…¥æ‰€æœ‰æµ‹è¯•æ¨¡å—
from test_date import *
from test_api_compatibility import *
from test_logging import *

# é™éŸ³Dateç±»çš„æ—¥å¿—ï¼Œé¿å…å¹²æ‰°æµ‹è¯•è¾“å‡º
from staran.tools.date import Date
Date.set_log_level(logging.CRITICAL)


class ColoredTextTestResult(unittest.TextTestResult):
    """å¸¦é¢œè‰²çš„æµ‹è¯•ç»“æœè¾“å‡º"""
    
    def __init__(self, stream, descriptions, verbosity):
        super().__init__(stream, descriptions, verbosity)
        self.verbosity = verbosity  # ç¡®ä¿verbosityå±æ€§å­˜åœ¨
        self.colors = {
            'green': '\033[92m',
            'red': '\033[91m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'purple': '\033[95m',
            'cyan': '\033[96m',
            'white': '\033[97m',
            'end': '\033[0m',
            'bold': '\033[1m'
        }
    
    def addSuccess(self, test):
        super().addSuccess(test)
        if self.verbosity > 1:
            self.stream.write(f"{self.colors['green']}âœ“{self.colors['end']} ")
            self.stream.writeln(f"{self.colors['green']}{self.getDescription(test)}{self.colors['end']}")
    
    def addError(self, test, err):
        super().addError(test, err)
        if self.verbosity > 1:
            self.stream.write(f"{self.colors['red']}âœ—{self.colors['end']} ")
            self.stream.writeln(f"{self.colors['red']}{self.getDescription(test)}{self.colors['end']}")
    
    def addFailure(self, test, err):
        super().addFailure(test, err)
        if self.verbosity > 1:
            self.stream.write(f"{self.colors['red']}âœ—{self.colors['end']} ")
            self.stream.writeln(f"{self.colors['red']}{self.getDescription(test)}{self.colors['end']}")
    
    def addSkip(self, test, reason):
        super().addSkip(test, reason)
        if self.verbosity > 1:
            self.stream.write(f"{self.colors['yellow']}âŠ{self.colors['end']} ")
            self.stream.writeln(f"{self.colors['yellow']}{self.getDescription(test)} (skipped: {reason}){self.colors['end']}")


class ColoredTestRunner(unittest.TextTestRunner):
    """å¸¦é¢œè‰²çš„æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, **kwargs):
        kwargs['resultclass'] = ColoredTextTestResult
        super().__init__(**kwargs)


def create_test_suite():
    """åˆ›å»ºå®Œæ•´æµ‹è¯•å¥—ä»¶"""
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æ‰€æœ‰æµ‹è¯•æ¨¡å—
    test_modules = [
        'test_date',
        'test_api_compatibility', 
        'test_logging'
    ]
    
    for module_name in test_modules:
        try:
            module = __import__(module_name)
            module_suite = loader.loadTestsFromModule(module)
            suite.addTest(module_suite)
        except ImportError as e:
            print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥æµ‹è¯•æ¨¡å— {module_name}: {e}")
    
    return suite


def run_test_category(category_name, test_classes):
    """è¿è¡Œç‰¹å®šç±»åˆ«çš„æµ‹è¯•"""
    print(f"\n{'='*60}")
    print(f"è¿è¡Œ {category_name} æµ‹è¯•")
    print(f"{'='*60}")
    
    suite = unittest.TestSuite()
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        suite.addTest(tests)
    
    runner = ColoredTestRunner(verbosity=2)
    start_time = time.time()
    result = runner.run(suite)
    end_time = time.time()
    
    print(f"\n{category_name} æµ‹è¯•å®Œæˆ")
    print(f"è¿è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’")
    print(f"æµ‹è¯•æ€»æ•°: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    print(f"è·³è¿‡: {len(result.skipped)}")
    
    return result


def main():
    """ä¸»å‡½æ•°"""
    print("Staran Date åº“æµ‹è¯•å¥—ä»¶")
    print("="*60)
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    print(f"æµ‹è¯•å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    all_results = []
    
    # 1. æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
    print("\nğŸ”§ è¿è¡Œæ ¸å¿ƒåŠŸèƒ½æµ‹è¯•...")
    core_tests = [
        TestDateCreation,
        TestDateClassMethods,
        TestDateConversion,
        TestDateFormatting,
        TestDateGetters,
        TestDatePredicates,
        TestDateArithmetic,
        TestDateComparison,
        TestDateCalculation,
        TestDateErrorHandling,
        TestBackwardCompatibility
    ]
    
    core_result = run_test_category("æ ¸å¿ƒåŠŸèƒ½", core_tests)
    all_results.append(("æ ¸å¿ƒåŠŸèƒ½", core_result))
    
    # 2. APIå…¼å®¹æ€§æµ‹è¯•
    print("\nğŸ”„ è¿è¡ŒAPIå…¼å®¹æ€§æµ‹è¯•...")
    api_tests = [
        TestAPICompatibility,
        TestMethodSignatures,
        TestAPIDocumentation,
        TestAPIEvolution
    ]
    
    api_result = run_test_category("APIå…¼å®¹æ€§", api_tests)
    all_results.append(("APIå…¼å®¹æ€§", api_result))
    
    # 3. æ—¥å¿—ç³»ç»Ÿæµ‹è¯•
    print("\nğŸ“ è¿è¡Œæ—¥å¿—ç³»ç»Ÿæµ‹è¯•...")
    logging_tests = [
        TestLoggingSystem,
        TestLoggingConfiguration,
        TestLoggingIntegration,
        TestLoggingEdgeCases
    ]
    
    logging_result = run_test_category("æ—¥å¿—ç³»ç»Ÿ", logging_tests)
    all_results.append(("æ—¥å¿—ç³»ç»Ÿ", logging_result))
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("="*60)
    
    total_tests = 0
    total_failures = 0
    total_errors = 0
    total_skipped = 0
    
    for category, result in all_results:
        total_tests += result.testsRun
        total_failures += len(result.failures)
        total_errors += len(result.errors)
        total_skipped += len(result.skipped)
        
        success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100) if result.testsRun > 0 else 0
        
        print(f"{category:20} | æµ‹è¯•: {result.testsRun:3d} | æˆåŠŸç‡: {success_rate:6.1f}% | å¤±è´¥: {len(result.failures):2d} | é”™è¯¯: {len(result.errors):2d}")
    
    print("-" * 60)
    overall_success_rate = ((total_tests - total_failures - total_errors) / total_tests * 100) if total_tests > 0 else 0
    print(f"{'æ€»è®¡':20} | æµ‹è¯•: {total_tests:3d} | æˆåŠŸç‡: {overall_success_rate:6.1f}% | å¤±è´¥: {total_failures:2d} | é”™è¯¯: {total_errors:2d}")
    
    # è¯¦ç»†å¤±è´¥å’Œé”™è¯¯æŠ¥å‘Š
    if total_failures > 0 or total_errors > 0:
        print("\n" + "="*60)
        print("å¤±è´¥å’Œé”™è¯¯è¯¦æƒ…")
        print("="*60)
        
        for category, result in all_results:
            if result.failures:
                print(f"\n{category} - å¤±è´¥:")
                for test, traceback in result.failures:
                    print(f"  âœ— {test}")
                    print(f"    {traceback.split('AssertionError:')[-1].strip() if 'AssertionError:' in traceback else 'è¯¦è§å®Œæ•´æ—¥å¿—'}")
            
            if result.errors:
                print(f"\n{category} - é”™è¯¯:")
                for test, traceback in result.errors:
                    print(f"  âœ— {test}")
                    print(f"    {traceback.split('\\n')[-2] if '\\n' in traceback else traceback}")
    
    print(f"\næµ‹è¯•å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    if total_failures > 0 or total_errors > 0:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥! å¤±è´¥: {total_failures}, é”™è¯¯: {total_errors}")
        return 1
    else:
        print(f"\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ€»è®¡ {total_tests} ä¸ªæµ‹è¯•")
        return 0


if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)
