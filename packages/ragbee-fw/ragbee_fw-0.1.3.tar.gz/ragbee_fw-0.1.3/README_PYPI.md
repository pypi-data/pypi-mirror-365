# RAGBee FW

*Lightweight Retrieval-Augmented-Generation framework for SMEs.*

RAGBee helps you **load documents â†’ split â†’ retrieve â†’ generate**  
with any LLM (OpenAI, HF Inference API, local vLLM/Triton).  
Ports & Adapters + DI give you clean extensibility; CLI lets you run the pipeline in three commands.

---

## âœ¨ Features

- **Clean architecture** â€” `core.ports` (contracts) + `infrastructure.*` (plug-ins)  
- **Dependency Injection** â€” YAML config â‡’ container wires loader / splitter / retriever / LLM  
- **CLI (`ragbee_cli`)** â€” `ingest`, `ask`, `shell` out of the box  
- **LLM agnostic** â€” OpenAI, HuggingFace Hub, vLLM, Triton â€¦ or your own adapter  
- **Composable** â€” embed in FastAPI, Telegram-bot, Streamlit, Airflow DAG  
- **MIT license** â€” free for commercial use

---

## ğŸš€ Quick start

```bash
pip install ragbee-fw           # 1. install

ragbee_cli ingest config.yml    # 2. build index
ragbee_cli ask config.yml "Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ RAG?"   # 3. ask
ragbee_cli shell config.yml     # â€¦or interactive REPL
```

#### config.yml (minimal):

```yaml
data_loader:
  type: file_loader
  path: ./data

text_chunker:
  type: recursive_splitter
  chunk_size: 500
  chunk_overlap: 100

retriever:
  type: bm25
  top_k: 3

llm:
  type: hf
  model_name: gpt-3.5-turbo
  token: ${env:HF_TOKEN}
```

## ğŸ§‘â€ğŸ’» Python API

```python

from ragbee_fw import DIContainer, load_config

cfg = load_config("config.yml")
container = DIContainer(cfg)

# 1) build / update index
ingestion = container.build_ingestion_service()
ingestion.build_index()                # or .update_index()

# 2) answer questions
answer = container.build_answer_service()
print(answer.generate_answer("What is RAG?", top_k=3))
```

## ğŸ—º Architecture (Clean / Hexagonal)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CLI / UI     â”‚  â†  FastAPI, Streamlit, Telegram Bot â€¦
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ adapter
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Application    â”‚  â†  DI container, services
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ports
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Core         â”‚  â†  pure dataclasses, protocols
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ adapters
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Infrastructure    â”‚  â†  FS-loader, Splitter, BM25, HF LLM â€¦
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Documentation

Docs & API â€” [README](https://github.com/droogg/ragbee_fw/blob/main/README.md)

Examples â€” [example/](https://github.com/droogg/ragbee_fw/tree/main/example)


## ğŸ¤ Contributing

1. Fork â†’ clone â†’ poetry install

2. Format code with black . && isort .

3. Submit PR â†’ CI will run lint & tests

See ```CONTRIBUTING.md``` for full guide.

### ğŸ“œ License
MIT Â© V.A. Shevchenko â€” free for any purpose, commercial or private.
