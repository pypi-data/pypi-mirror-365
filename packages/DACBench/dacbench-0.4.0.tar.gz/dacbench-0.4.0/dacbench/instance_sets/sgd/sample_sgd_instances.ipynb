{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "batch_size = [32, 1024]\n",
    "optimizer_types = [\"AdamW\", \"Adam\", \"RMSprop\", \"SGD\"]\n",
    "seed = [0, 2**32 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mnist_model = [\n",
    "    (\n",
    "        \"CONV2D\",\n",
    "        {\"in_channels\": 1, \"out_channels\": 32, \"kernel_size\": 3},\n",
    "    ),\n",
    "    (\"RELU\", {}),\n",
    "    (\n",
    "        \"CONV2D\",\n",
    "        {\"in_channels\": 32, \"out_channels\": 64, \"kernel_size\": 3},\n",
    "    ),\n",
    "    (\"RELU\", {}),\n",
    "    (\"POOLING\", {\"kernel_size\": 2}),\n",
    "    (\"DROPOUT\", {\"p\": 0.25}),\n",
    "    (\"FLATTEN\", {}),\n",
    "    (\"LINEAR\", {\"in_features\": 9216, \"out_features\": 128}),\n",
    "    (\"RELU\", {}),\n",
    "    (\"DROPOUT\", {\"p\": 0.5}),\n",
    "    (\"LINEAR\", {\"in_features\": 128, \"out_features\": 10}),\n",
    "    (\"LOGSOFTMAX\", {\"dim\": 1}),\n",
    "]\n",
    "small_cifar_model = [\n",
    "    (\n",
    "        \"CONV2D\",\n",
    "        {\"in_channels\": 3, \"out_channels\": 6, \"kernel_size\": 5},\n",
    "    ),\n",
    "    (\"POOLING\", {\"kernel_size\": 2}),\n",
    "    (\n",
    "        \"CONV2D\",\n",
    "        {\"in_channels\": 6, \"out_channels\": 16, \"kernel_size\": 5},\n",
    "    ),\n",
    "    (\"POOLING\", {\"kernel_size\": 2}),\n",
    "    (\"FLATTEN\", {}),\n",
    "    (\"LINEAR\", {\"in_features\": 16 * 5 * 5, \"out_features\": 120}),\n",
    "    (\"RELU\", {}),\n",
    "    (\"LINEAR\", {\"in_features\": 120, \"out_features\": 84}),\n",
    "    (\"RELU\", {}),\n",
    "    (\"LINEAR\", {\"in_features\": 84, \"out_features\": 10}),\n",
    "    (\"LOGSOFTMAX\", {\"dim\": 1}),\n",
    "]\n",
    "\n",
    "with open(\"small_mnist_model.json\", \"w+\") as f:\n",
    "    json.dump(small_mnist_model, f)\n",
    "with open(\"small_cifar_model.json\", \"w+\") as f:\n",
    "    json.dump(small_cifar_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [\"small_mnist_model.json\", \"small_cifar_model.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cifar_instances(file_name, num_instances):\n",
    "    dataset = \"CIFAR10\"\n",
    "    train_validation_ratio = 0.8\n",
    "    fraction_of_dataset = 1\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    with open(file_name, \"w+\") as f:\n",
    "        header_string = \"id,dataset,model_type,model_kwargs,optimizer,optimizer_params,seed,batch_size,train_validation_ratio,fraction_of_dataset\\n\"\n",
    "        f.write(header_string)\n",
    "        for i in range(num_instances):\n",
    "            instance_string = f\"{i},{dataset},from_file,small_cifar_model.json,{rng.choice(optimizer_types)},,{rng.choice(seed)},{rng.choice(batch_size)},{train_validation_ratio},{fraction_of_dataset}\\n\"\n",
    "            f.write(instance_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cifar_instances(\"sgd_cifar10_variations_train.csv\", 10)\n",
    "sample_cifar_instances(\"sgd_cifar10_variations_test.csv\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_resnet_instances(file_name, num_instances):\n",
    "    model_kwargs = \"'pytorch/vision:v0.10.0-resnet18-False\"\n",
    "    datasets = [\"CIFAR10\", \"MNIST\", \"FashionMNIST\"]\n",
    "    train_validation_ratio = 0.8\n",
    "    fraction_of_dataset = 1\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    with open(file_name, \"w+\") as f:\n",
    "        header_string = \"id,dataset,model_type,model_kwargs,optimizer,optimizer_params,seed,batch_size,train_validation_ratio,fraction_of_dataset\\n\"\n",
    "        f.write(header_string)\n",
    "        for i in range(num_instances):\n",
    "            instance_string = f\"{i},{rng.choice(datasets)},from_torchhub,{model_kwargs},{rng.choice(optimizer_types)},,{rng.choice(seed)},{rng.choice(batch_size)},{train_validation_ratio},{fraction_of_dataset}\\n\"\n",
    "            f.write(instance_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_resnet_instances(\"sgd_resnet18_variations_train.csv\", 10)\n",
    "sample_resnet_instances(\"sgd_resnet18_variations_test.csv\", 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
