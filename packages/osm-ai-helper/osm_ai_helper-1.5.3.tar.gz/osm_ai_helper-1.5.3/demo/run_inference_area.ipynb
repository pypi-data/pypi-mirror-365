{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference across an entire area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRgdm5dxRt9P"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oInr5YvtvSGo"
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade git+https://github.com/mozilla-ai/osm-ai-helper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFBW1o0KT2-Q"
   },
   "source": [
    "## Setup Secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfJK3WGUhtZ"
   },
   "source": [
    "You need to set the following secrets in the notebook.\n",
    "\n",
    "Check the [Authorization Guide](https://mozilla-ai.github.io/osm-ai-helper/authorization) in the docs to learn how to obtain them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2E1XhnrQT4X1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"MAPBOX_TOKEN\"] = userdata.get(\"MAPBOX_TOKEN\")\n",
    "os.environ[\"OSM_CLIENT_ID\"] = userdata.get(\"OSM_CLIENT_ID\")\n",
    "os.environ[\"OSM_CLIENT_SECRET\"] = userdata.get(\"OSM_CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sciFo618-5jn"
   },
   "source": [
    "## Download Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Lhl6jVJRwtX"
   },
   "source": [
    "You can check the [Create Dataset](https://colab.research.google.com/github/mozilla-ai//osm-ai-helper/blob/main/demo/create_dataset.ipyn) and [Finetune Model](https://colab.research.google.com/github/mozilla-ai//osm-ai-helper/blob/main/demo/finetune_model.ipynb) notebooks to learn how to train your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N63q16Kxt_d5"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9_p-0LEuStk"
   },
   "outputs": [],
   "source": [
    "hf_hub_download(\n",
    "    \"mozilla-ai/swimming-pool-detector\",\n",
    "    filename=\"model.pt\",\n",
    "    repo_type=\"model\",\n",
    "    local_dir=\"models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHhfCLGaRmIj"
   },
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AREA_NAME` can be city, state, country, etc.\n",
    "\n",
    "Uses the [Nominatim API](https://nominatim.org/release-docs/develop/api/Search/).\n",
    "\n",
    "Large areas will take more time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1yUCZPkghiA"
   },
   "outputs": [],
   "source": [
    "AREA_NAME = None\n",
    "\n",
    "if AREA_NAME is None:\n",
    "    raise RuntimeError(\"Need to provide an area name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSImORMAgY9C"
   },
   "source": [
    "## Split AREA_NAME into lat_lon inputs for `run_inference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJZFcW6Agkeh"
   },
   "outputs": [],
   "source": [
    "from osm_ai_helper.utils.inference import split_area_into_lat_lon_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45vm4uGQhD4t",
    "outputId": "876619d9-7789-4091-f896-fe11ce7aac57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon_centers = split_area_into_lat_lon_centers(AREA_NAME, 18, 2)\n",
    "print(f\"Number of `run_inference` calls: {len(lat_lon_centers)}\")\n",
    "print(f\"Will take aproximatelly {len(lat_lon_centers) / 10} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzS_1i3khGah"
   },
   "source": [
    "## Run inference across the entire area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it takes too long to process the entire area and you want to process by parts,\n",
    "you can interrupt the inference and set `ALREADY_PROCESSED` to number of the last lat_lon_center\n",
    "you processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Xf6CaV7sJgJ"
   },
   "outputs": [],
   "source": [
    "ALREADY_PROCESSED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcmE3BunAAfb"
   },
   "outputs": [],
   "source": [
    "from osm_ai_helper.run_inference import run_inference\n",
    "\n",
    "for n, (lat, lon) in enumerate(lat_lon_centers[ALREADY_PROCESSED:]):\n",
    "    print(f\"{n + ALREADY_PROCESSED} of {len(lat_lon_centers)}\")\n",
    "    output_path, existing, new, missing = run_inference(\n",
    "        \"models/model.pt\",\n",
    "        output_dir=\"results\",\n",
    "        lat_lon=(lat, lon),\n",
    "        margin=2,\n",
    "        save_full_images=False,\n",
    "        batch_size=64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "642Ay6nLsOKc"
   },
   "source": [
    "# Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itfQlkogsP6v"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "results = Path(\"results\")\n",
    "merged = Path(\"merged\")\n",
    "merged.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for location in results.iterdir():\n",
    "    new_polygons = list(location.glob(\"*.json\"))\n",
    "    if not new_polygons:\n",
    "        location.rmdir()\n",
    "        continue\n",
    "    for new_polygon in new_polygons:\n",
    "        shutil.copy(new_polygon, merged / f\"{location.name}-{new_polygon.name}\")\n",
    "        shutil.copy(\n",
    "            new_polygon.with_suffix(\".png\"),\n",
    "            merged / f\"{location.name}-{new_polygon.with_suffix('.png').name}\",\n",
    "        )\n",
    "        shutil.copy(\n",
    "            f\"{location}/{new_polygon.stem}_painted.png\",\n",
    "            merged / f\"{location.name}-{new_polygon.stem}_painted.png\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(merged.glob(\"*.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXz98rz_AmfA"
   },
   "source": [
    "# Manually Filter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXq6-70I8BD_"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for new_polygon in Path(\"merged\").glob(\"*.json\"):\n",
    "    raw_image = new_polygon.with_suffix(\".png\")\n",
    "    painted_image = f\"{new_polygon.parent}/{new_polygon.stem}_painted.png\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Assuming raw_image_path and painted_image_path are image file paths\n",
    "    axes[0].imshow(plt.imread(raw_image))\n",
    "    axes[0].set_title(\"Raw Image\")\n",
    "\n",
    "    axes[1].imshow(plt.imread(painted_image))\n",
    "    axes[1].set_title(\"Painted Image\")\n",
    "\n",
    "    plt.show()\n",
    "    time.sleep(1.5)\n",
    "\n",
    "    user_input = input(\"Keep image? (Y/N): \")\n",
    "\n",
    "    if user_input.upper() == \"Y\":\n",
    "        keep_folder = Path(\"keep\")\n",
    "        keep_folder.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(new_polygon, keep_folder / new_polygon.name)\n",
    "        print(f\"Images moved to {keep_folder}\")\n",
    "    else:\n",
    "        discard_folder = Path(\"discard\")\n",
    "        discard_folder.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(new_polygon, discard_folder / new_polygon.name)\n",
    "        print(f\"Images moved to {discard_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6QrI0Rz-x7s"
   },
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will be exported in [OsmChange](https://wiki.openstreetmap.org/wiki/OsmChange) format.\n",
    "\n",
    "You can then import the file in [any of the supported editors](https://wiki.openstreetmap.org/wiki/OsmChange#Editors) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xieekjm3BSEI"
   },
   "outputs": [],
   "source": [
    "from osm_ai_helper.export_osm import export_osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Abc-2nTB9RsR"
   },
   "outputs": [],
   "source": [
    "export_osm(\n",
    "    results_dir=output_path / \"keep\",\n",
    "    output_dir=\"exported\",\n",
    "    tags={\"leisure\": \"swimming_pool\", \"access\": \"private\", \"location\": \"outdoor\"},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
