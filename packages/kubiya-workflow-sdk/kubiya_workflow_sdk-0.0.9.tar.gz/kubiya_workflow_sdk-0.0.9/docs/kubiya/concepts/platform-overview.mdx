---
title: "Platform Overview"
sidebarTitle: "Platform Overview"
description: Enterprise AI automation platform with Serverless Agents, Container Tools, and Policy Enforcement
icon: layer-group
---

# Kubiya Platform Overview

Kubiya is the **first LLM-native automation platform** that runs **entirely on your infrastructure**. Unlike traditional automation platforms, Kubiya is designed from the ground up for AI agents with **Serverless Container Tools**, **LLM-Friendly DAG Workflows**, and **Zero-Trust Security** - all executing in your own environment.

## ğŸ¯ What Makes Kubiya Unique

<CardGroup cols={2}>
  <Card title="ğŸ§  LLM-Native Design" icon="brain">
    **Built for AI agents** - Every tool and workflow is designed to be easily understood and executed by LLMs
  </Card>
  
  <Card title="ğŸ  Your Infrastructure" icon="home">
    **Runs on your infra** - Complete control and security with self-hosted runners in your own environment
  </Card>
  
  <Card title="ğŸ“Š LLM-Friendly DAG Workflows" icon="project-diagram">
    **Visual workflows** that LLMs can understand, modify, and execute with natural language descriptions
  </Card>
  
  <Card title="ğŸ› ï¸ True Serverless Tools" icon="container">
    **Container-native tools** that scale to zero, start instantly, and run any language or framework
  </Card>
</CardGroup>

## ğŸ—ï¸ LLM-Native Architecture

```mermaid
graph TB
    subgraph "ğŸ§  AI Layer"
        LLM["ğŸ¤– LLM/AI Assistant<br/>Claude, ChatGPT, Custom"]
        MCP["ğŸ”Œ MCP Server<br/>Zero Dependencies"]
        CLI["âš¡ Kubiya CLI<br/>Single Binary"]
    end
    
    subgraph "â˜ï¸ Kubiya Control Plane"
        API["ğŸŒ API Gateway<br/>Stateless & Scalable"]
        Auth["ğŸ” Authentication<br/>OIDC/SAML/API Keys"]
        Policies["ğŸ›¡ï¸ OPA Policy Engine<br/>Pre-execution Validation"]
        Orchestrator["ğŸ­ Workflow Orchestrator<br/>LLM-Friendly DAGs"]
        KB["ğŸ“š Knowledge Base<br/>Semantic Search"]
    end
    
    subgraph "ğŸ  Your Infrastructure (Self-Hosted)"
        direction TB
        subgraph "ğŸƒ Execution Runners"
            K8sRunner["âš™ï¸ Kubernetes Runner<br/>Auto-scaling Pods"]
            DockerRunner["ğŸ³ Docker Runner<br/>Local Containers"]
            VMRunner["ğŸ’» VM Runner<br/>Direct Execution"]
        end
        
        subgraph "ğŸ› ï¸ Serverless Tools"
            PyTool["ğŸ Python Tools<br/>pandas, numpy, ML"]
            NodeTool["ğŸ“¦ Node.js Tools<br/>APIs, automation"]
            GoTool["âš¡ Go Tools<br/>CLI, performance"]
            BashTool["ğŸ’» Bash Tools<br/>System operations"]
        end
        
        subgraph "ğŸ”— Your Resources"
            K8S["âš™ï¸ Kubernetes Clusters"]
            Cloud["â˜ï¸ AWS/Azure/GCP"]
            DB["ğŸ—„ï¸ Databases"]
            APIs["ğŸ”Œ Internal APIs"]
        end
    end
    
    %% Connections
    LLM -.->|"ğŸ“¡ MCP Protocol"| MCP
    MCP -.->|"ğŸ” Authenticated"| CLI
    CLI -->|"ğŸ“Š Telemetry Only"| API
    API --> Auth
    Auth --> Policies
    Policies --> Orchestrator
    Orchestrator -.->|"ğŸ“‹ Task Assignment"| K8sRunner
    Orchestrator -.->|"ğŸ“‹ Task Assignment"| DockerRunner
    Orchestrator -.->|"ğŸ“‹ Task Assignment"| VMRunner
    
    K8sRunner --> PyTool
    K8sRunner --> NodeTool
    DockerRunner --> GoTool
    VMRunner --> BashTool
    
    PyTool --> K8S
    NodeTool --> Cloud
    GoTool --> DB
    BashTool --> APIs
    
    %% Styling
    classDef ai fill:#e1f5fe
    classDef control fill:#f3e5f5
    classDef infra fill:#e8f5e8
    classDef tools fill:#fff3e0
    
    class LLM,MCP,CLI ai
    class API,Auth,Policies,Orchestrator,KB control
    class K8sRunner,DockerRunner,VMRunner,K8S,Cloud,DB,APIs infra
    class PyTool,NodeTool,GoTool,BashTool tools
```

### ğŸ”‘ Key Architecture Principles

1. **ğŸ  Your Infrastructure First**: All execution happens in your environment
2. **ğŸ§  LLM-Native**: Every component designed for AI agent interaction
3. **ğŸ“Š Minimal Data Transfer**: Only metadata and telemetry leave your infrastructure
4. **ğŸ›¡ï¸ Zero-Trust Security**: Policy validation before any execution
5. **âš¡ Serverless Execution**: Tools scale to zero when not in use

## ğŸ¯ Core Capabilities

### 1. **ğŸ› ï¸ True Serverless Container Tools**

**What makes them special**: Unlike traditional serverless functions with cold starts and language limitations, Kubiya's serverless tools are **container-native** and **LLM-optimized**.

```mermaid
graph LR
    subgraph "ğŸ”¥ Traditional Serverless (AWS Lambda, etc.)"
        direction TB
        CS["â„ï¸ Cold Starts<br/>300ms-10s"]
        LL["ğŸ”’ Language Lock-in<br/>Python, Node.js only"]
        SM["ğŸ“ Size Limits<br/>250MB max"]
        TL["â±ï¸ Time Limits<br/>15min max"]
    end
    
    subgraph "âš¡ Kubiya Serverless Tools"
        direction TB
        IS["ğŸš€ Instant Start<br/>50-100ms"]
        AL["ğŸŒ Any Language<br/>Python, Go, Rust, etc."]
        AS["ğŸ“¦ Any Size<br/>Full Docker images"]
        UT["â³ Unlimited Time<br/>Long-running jobs"]
    end
    
    CS -.->|"vs"| IS
    LL -.->|"vs"| AL
    SM -.->|"vs"| AS
    TL -.->|"vs"| UT
```

**ğŸ¯ LLM-Optimized Features**:
- **ğŸ“ Natural Language Descriptions**: Each tool has LLM-friendly documentation
- **ğŸ” Semantic Discovery**: LLMs can find tools by describing what they need
- **âš¡ Instant Scaling**: From 0 to 1000+ containers in seconds
- **ğŸ  Your Infrastructure**: Run on your Kubernetes, Docker, or VMs
- **ğŸ“Š Live Streaming**: Real-time output for LLM feedback

**Example Tool Definition**:
```json
{
  "name": "analyze-logs",
  "description": "Analyze application logs for errors and patterns",
  "llm_prompt": "Use this tool when you need to investigate application issues, find error patterns, or analyze log data. It supports JSON, text, and structured logs.",
  "image": "python:3.11-slim",
  "packages": ["pandas", "numpy", "matplotlib"],
  "integrations": ["aws/s3", "elasticsearch"],
  "scaling": {
    "min_instances": 0,
    "max_instances": 100,
    "scale_to_zero_timeout": "5m"
  }
}
```

### 2. **ğŸ“Š LLM-Friendly DAG Workflows**

**What makes them special**: Traditional workflows are code-heavy and hard for LLMs to understand. Kubiya workflows are **declarative**, **visual**, and **LLM-optimized**.

```mermaid
graph TD
    subgraph "ğŸ§  LLM-Friendly Workflow"
        Start(["ğŸš€ Start: Deploy App"])
        Check{"ğŸ” Environment Check<br/>Is staging healthy?"}
        Build["ğŸ”¨ Build Container<br/>docker build -t app:v2.1"]
        Test["ğŸ§ª Run Tests<br/>pytest --cov=80%"]
        Deploy["ğŸš€ Deploy to Staging<br/>kubectl apply -f staging/"]
        Validate{"âœ… Health Check<br/>All endpoints responding?"}
        Promote["ğŸ¯ Promote to Production<br/>kubectl apply -f prod/"]
        Rollback["âª Rollback<br/>kubectl rollout undo"]
        Notify["ğŸ“¢ Notify Team<br/>Slack + Email"]
        End(["âœ… Complete"])
        
        Start --> Check
        Check -->|"âœ… Healthy"| Build
        Check -->|"âŒ Unhealthy"| Notify
        Build --> Test
        Test -->|"âœ… Pass"| Deploy
        Test -->|"âŒ Fail"| Notify
        Deploy --> Validate
        Validate -->|"âœ… Healthy"| Promote
        Validate -->|"âŒ Unhealthy"| Rollback
        Promote --> Notify
        Rollback --> Notify
        Notify --> End
    end
    
    %% Styling
    classDef success fill:#e8f5e8
    classDef warning fill:#fff3e0
    classDef error fill:#ffebee
    classDef decision fill:#e3f2fd
    
    class Start,Build,Test,Deploy,Promote,End success
    class Notify warning
    class Rollback error
    class Check,Validate decision
```

**ğŸ§  LLM-Optimized Features**:
- **ğŸ“ Natural Language Steps**: Each step has human-readable descriptions
- **ğŸ¯ Intent-Based**: Focus on "what" not "how"
- **ğŸ” Self-Documenting**: Workflows explain themselves to LLMs
- **ğŸ”„ Dynamic**: LLMs can modify workflows on-the-fly
- **ğŸ“Š Visual**: Mermaid diagrams auto-generated for LLM understanding

**Example: LLM Creating a Workflow**
```python
# LLM Request: "Create a data pipeline that processes user events"
# Kubiya generates:

workflow = {
    "name": "user-events-pipeline",
    "description": "Process and analyze user events from multiple sources",
    "llm_summary": "This workflow extracts user events from Kafka, transforms them with pandas, validates data quality, and loads into data warehouse",
    "steps": [
        {
            "name": "extract-events",
            "description": "Extract user events from Kafka topics",
            "tool": "kafka-consumer",
            "args": {"topics": ["user-clicks", "user-views"]}
        },
        {
            "name": "transform-data",
            "description": "Clean and transform event data using pandas",
            "tool": "python-pandas",
            "depends_on": ["extract-events"]
        },
        {
            "name": "load-warehouse",
            "description": "Load processed data into Snowflake",
            "tool": "snowflake-loader",
            "depends_on": ["transform-data"]
        }
    ]
}
```

### 3. **ğŸ  Your Infrastructure Execution**

**Why this matters**: Most AI platforms send your data to their cloud. Kubiya keeps everything in your infrastructure for **security**, **compliance**, and **performance**.

```mermaid
graph TB
    subgraph "â˜ï¸ Traditional AI Platforms"
        YourData1["ğŸ¢ Your Data"]
        TheirCloud["â˜ï¸ Third-Party Cloud<br/>âŒ Data leaves your network<br/>âŒ Compliance risks<br/>âŒ Vendor lock-in"]
        Processing["âš™ï¸ Processing<br/>âŒ No control<br/>âŒ Limited resources"]
        
        YourData1 --> TheirCloud
        TheirCloud --> Processing
    end
    
    subgraph "ğŸ  Kubiya Architecture"
        YourData2["ğŸ¢ Your Data"]
        YourInfra["ğŸ  Your Infrastructure<br/>âœ… Data stays local<br/>âœ… Full compliance<br/>âœ… No vendor lock-in"]
        YourProcessing["âš™ï¸ Your Processing<br/>âœ… Full control<br/>âœ… Unlimited resources"]
        
        YourData2 --> YourInfra
        YourInfra --> YourProcessing
    end
    
    %% Styling
    classDef bad fill:#ffebee
    classDef good fill:#e8f5e8
    
    class TheirCloud,Processing bad
    class YourInfra,YourProcessing good
```

**ğŸ”’ Security & Compliance Benefits**:
- **ğŸ  Data Locality**: Your data never leaves your infrastructure
- **ğŸ›¡ï¸ Zero Trust**: Every action validated by your policies
- **ğŸ“‹ Compliance**: GDPR, SOC2 - your rules, your infrastructure
- **ğŸ” Air-Gapped**: Works completely offline if needed
- **ğŸ‘ï¸ Full Visibility**: Complete audit trails in your systems

**âš¡ Performance Benefits**:
- **ğŸš€ Low Latency**: Direct access to your resources
- **ğŸ”„ No API Limits**: Scale based on your infrastructure
- **ğŸ’¾ Data Efficiency**: No data transfer overhead
- **ğŸ¯ Resource Optimization**: Use your existing capacity

### 4. **ğŸ§  LLM-Native Design Philosophy**

Everything in Kubiya is designed for AI agents to understand and use effectively:

```mermaid
mindmap
  root)ğŸ§  LLM-Native Design(
    ğŸ“ Documentation
      Natural Language
      Examples Included
      Intent-Based
    ğŸ” Discovery
      Semantic Search
      Tag-Based
      Auto-Suggestions
    ğŸ¯ Execution
      Self-Describing
      Progress Updates
      Error Context
    ğŸ”„ Feedback
      Success Metrics
      Failure Analysis
      Improvement Hints
```

**ğŸ“ LLM-Friendly Documentation**:
- Every tool has natural language descriptions
- Use cases and examples included
- Common failure modes documented
- Alternative tool suggestions

**ğŸ” Intelligent Discovery**:
- LLMs can find tools by describing intent
- Semantic search across all capabilities
- Auto-suggest related tools and workflows
- Context-aware recommendations

## ğŸ¯ Next Steps

<CardGroup cols={2}>
  <Card title="ğŸš€ Quick Start" icon="rocket" href="/getting-started/quickstart">
    Get started in 5 minutes
  </Card>
  
  <Card title="ğŸ”§ MCP Integration" icon="plug" href="/mcp/overview">
    Connect your AI assistant
  </Card>
  
  <Card title="ğŸ› ï¸ Tool Development" icon="wrench" href="/concepts/workflows">
    Build your first tools
  </Card>
  
  <Card title="ğŸƒ Runner Setup" icon="running" href="/concepts/runners">
    Deploy execution infrastructure
  </Card>
</CardGroup>

---

**Ready to build enterprise-grade AI applications?** Kubiya provides the production infrastructure, security, and scale you need to deploy AI automation that actually works in the real world.
