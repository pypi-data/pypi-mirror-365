---
title: "Compose API"
sidebarTitle: "Compose"
description: End-to-end workflow generation and execution API
icon: wand-magic-sparkles
api: "POST /compose"
---

<Note>
  The Compose API is the main entry point for AI-powered workflow generation. It handles everything from understanding your request to generating and optionally executing workflows.
</Note>

## Overview

The `compose()` method provides a unified interface for:

- **Natural language to workflow** transformation
- **Automatic validation** and refinement
- **Optional execution** with streaming
- **Multiple output formats** (JSON, YAML, streaming)

## HTTP Endpoint

```http
POST /compose
Content-Type: application/json
Authorization: Bearer your-api-key
```

### Request Body

<ParamField body="task" type="string" required>
  The task description in natural language. Be specific and include requirements.
  
  **Examples:**
  - "Create a workflow to backup PostgreSQL databases daily"
  - "Deploy a containerized app to Kubernetes with health checks"
  - "Set up CI/CD pipeline for Python project with tests"
</ParamField>

<ParamField body="context" type="object" optional>
  Additional context to guide workflow generation.
  
  <Expandable title="Context Properties">
    <ParamField body="context.preferred_runner" type="string">
      Specific runner to use for execution
    </ParamField>
    <ParamField body="context.available_tools" type="array">
      List of tools/commands available
    </ParamField>
    <ParamField body="context.constraints" type="array">
      Security or operational constraints
    </ParamField>
    <ParamField body="context.environment" type="string">
      Target environment details
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="parameters" type="object" optional>
  Execution parameters (only used in `act` mode).
</ParamField>

<ParamField body="mode" type="string" default="plan">
  Operation mode:
  - `"plan"`: Generate workflow only
  - `"act"`: Generate and execute workflow
</ParamField>

<ParamField body="stream" type="boolean" default="true">
  Enable streaming response. When `true`, returns Server-Sent Events.
</ParamField>

<ParamField body="stream_format" type="string" default="sse">
  Streaming format:
  - `"sse"`: Server-Sent Events format
  - `"vercel"`: Vercel AI SDK format
  - `null`: Raw ADK events
</ParamField>

<ParamField body="session_id" type="string" optional>
  Session ID for conversation continuity. Automatically generated if not provided.
</ParamField>

<ParamField body="user_id" type="string" optional>
  User ID for namespacing and tracking. Defaults to `"default_user"`.
</ParamField>

## Response Format

<CodeGroup>

```json Plan Mode Response
{
  "workflow": {
    "name": "backup-databases",
    "description": "Automated database backup workflow",
    "runner": "kubiya-hosted",
    "steps": [
      {
        "name": "backup_postgres",
        "tool": "pg_dump",
        "parameters": {
          "database": "production",
          "output": "/backups/db-backup.sql"
        }
      }
    ]
  },
  "metadata": {
    "generated_at": "2024-01-15T10:30:00Z",
    "model": "gpt-4o",
    "tokens_used": 1250
  }
}
```

```json Act Mode Response  
{
  "workflow": {
    "name": "backup-databases",
    "description": "Automated database backup workflow",
    "runner": "kubiya-hosted",
    "steps": [...]
  },
  "execution_result": {
    "run_id": "run_abc123",
    "status": "success",
    "outputs": {
      "backup_file": "/backups/db-backup-20240115.sql",
      "size": "2.5GB"
    },
    "duration": 45.2,
    "started_at": "2024-01-15T10:30:00Z",
    "completed_at": "2024-01-15T10:30:45Z"
  }
}
```

</CodeGroup>

## Usage Examples

<CodeGroup>

```bash cURL Example
curl -X POST http://localhost:8001/compose \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "task": "Deploy my Node.js app to Kubernetes staging",
    "mode": "plan",
    "context": {
      "environment": "staging",
      "preferred_runner": "k8s-staging"
    }
  }'
```

```python Python SDK icon="python"
from kubiya_workflow_sdk.providers import get_provider

# Initialize ADK provider
adk = get_provider("adk")

# Generate a simple workflow
result = await adk.compose(
    task="Create a workflow to check disk space and alert if > 80%",
    mode="plan",
    stream=False
)

workflow = result["workflow"]
print(f"Generated: {workflow['name']}")
```

```typescript TypeScript SDK icon="typescript"
import { OrchestrationClient } from '@kubiya/sdk';

const client = new OrchestrationClient('http://localhost:8001', 'your-api-key');

// Generate workflow
const result = await client.compose({
  task: "Deploy application to staging environment",
  mode: "plan",
  context: {
    environment: "staging",
    preferred_runner: "k8s-staging"
  }
});

console.log('Generated workflow:', result.workflow.name);
```

```javascript JavaScript Fetch icon="square-js"
const response = await fetch('http://localhost:8001/compose', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer your-api-key'
  },
  body: JSON.stringify({
    task: "Set up monitoring for my microservices",
    mode: "plan",
    context: {
      services: ["api", "web", "worker"],
      monitoring_tool: "prometheus"
    }
  })
});
```

</CodeGroup>

## Streaming Examples

<CodeGroup>

```python Streaming Generation icon="python" lines
# Stream the generation process
async for event in adk.compose(
    task="Deploy application to Kubernetes",
    mode="plan",
    stream=True
):
    # Handle SSE events
    if event.startswith("data: "):
        data = json.loads(event[6:])
        print(f"{data['type']}: {data.get('content', '')}")
```

```typescript Server-Sent Events icon="typescript" lines
const response = await fetch('http://localhost:8001/compose', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer your-api-key'
  },
  body: JSON.stringify({
    task: "Deploy to production",
    mode: "act",
    stream: true
  })
});

const reader = response.body?.getReader();
const decoder = new TextDecoder();

while (reader) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  const lines = chunk.split('\n');
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const event = JSON.parse(line.slice(6));
      console.log(`Event: ${event.type}`, event);
    }
  }
}
```

```bash Streaming with cURL icon="terminal" lines
curl -X POST http://localhost:8001/compose \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -H "Accept: text/event-stream" \
  -N \
  -d '{
    "task": "Deploy my application",
    "mode": "act", 
    "stream": true
  }'
```

</CodeGroup>

## Event Types

When streaming is enabled, various event types are emitted:

<CodeGroup>

```json Generation Events
// Text generation progress
{"type": "text", "content": "Analyzing requirements..."}

// Tool calls (loading context)
{"type": "tool_call", "name": "get_runners", "arguments": {}}

// Tool results  
{"type": "tool_result", "name": "get_runners", "result": [...]}

// Workflow ready
{"type": "workflow", "data": {...}}
```

```json Execution Events (Act Mode)
// Execution started
{"type": "execution_start", "workflow": "deploy-app", "run_id": "run_123"}

// Step progress
{"type": "step_start", "step": "build", "index": 0}
{"type": "step_output", "step": "build", "output": "Building..."}
{"type": "step_complete", "step": "build", "status": "success"}

// Execution complete
{"type": "execution_complete", "status": "success", "duration": 120.5}
```

</CodeGroup>

## Error Handling

The compose API handles various error scenarios:

<AccordionGroup>
  <Accordion title="Generation Errors" icon="triangle-exclamation">
    ```python
    try:
        result = await adk.compose(task="...")
    except ProviderError as e:
        # Handle generation failures
        print(f"Generation failed: {e}")
    ```
  </Accordion>
  
  <Accordion title="Validation Errors" icon="code">
    ```python
    # Validation errors are automatically handled
    # The AI will attempt to fix them
    # But you can set limits:
    
    config = ADKConfig(max_loop_iterations=2)
    adk = get_provider("adk", config=config)
    ```
  </Accordion>
  
  <Accordion title="Execution Errors" icon="play">
    ```python
    async for event in adk.compose(task="...", mode="act"):
        if event.get("type") == "error":
            # Handle execution errors
            logger.error(f"Execution error: {event['message']}")
            # Decide whether to continue or abort
    ```
  </Accordion>
  
  <Accordion title="Timeout Errors" icon="clock">
    ```python
    import asyncio
    
    try:
        async with asyncio.timeout(300):  # 5 minute timeout
            result = await adk.compose(task="...")
    except asyncio.TimeoutError:
        print("Generation timed out")
    ```
  </Accordion>
</AccordionGroup>

## Advanced Configuration

### Custom Models

```python
from kubiya_workflow_sdk.providers.adk import ADKConfig

config = ADKConfig(
    model_overrides={
        "workflow_generator": "together_ai/Qwen/QwQ-32B-Preview",
        "refinement": "together_ai/deepseek-ai/DeepSeek-V3"
    }
)

adk = get_provider("adk", config=config)
```

### Performance Tuning

```python
config = ADKConfig(
    max_loop_iterations=5,      # More refinement attempts
    timeout=600,                # 10 minute timeout
    enable_caching=True,        # Cache context loading
    stream_buffer_size=2048     # Larger streaming buffer
)
```

### Custom Filters

```python
# Filter streaming events
async for event in adk.compose(
    task="...",
    stream=True,
    stream_filter={
        "include_tool_calls": False,  # Skip tool events
        "include_thoughts": True,      # Include reasoning
        "min_importance": "medium"     # Filter by importance
    }
):
    process_filtered_event(event)
```

## Integration Examples

### FastAPI Endpoint

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

class ComposeRequest(BaseModel):
    task: str
    mode: str = "plan"
    context: dict = {}
    parameters: dict = {}

@app.post("/api/compose")
async def compose_workflow(request: ComposeRequest):
    try:
        adk = get_provider("adk")
        
        if request.mode == "plan":
            # Non-streaming for plan mode
            result = await adk.compose(
                task=request.task,
                context=request.context,
                mode="plan",
                stream=False
            )
            return result
        else:
            # For act mode, use websocket instead
            raise HTTPException(
                status_code=400,
                detail="Use WebSocket endpoint for act mode"
            )
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### WebSocket Streaming

```python
from fastapi import WebSocket
import json

@app.websocket("/ws/compose")
async def compose_stream(websocket: WebSocket):
    await websocket.accept()
    
    try:
        # Receive request
        data = await websocket.receive_json()
        
        adk = get_provider("adk")
        
        # Stream responses
        async for event in adk.compose(
            task=data["task"],
            mode=data.get("mode", "plan"),
            context=data.get("context", {}),
            parameters=data.get("parameters", {}),
            stream=True,
            stream_format="vercel"
        ):
            await websocket.send_text(event)
            
    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "message": str(e)
        })
    finally:
        await websocket.close()
```

## Best Practices

<CardGroup cols={2}>
  <Card title="Be Specific" icon="bullseye">
    Provide detailed task descriptions for better results
  </Card>
  <Card title="Use Context" icon="info">
    Include relevant context about your environment
  </Card>
  <Card title="Handle Errors" icon="shield">
    Always implement proper error handling
  </Card>
  <Card title="Monitor Usage" icon="chart-line">
    Track token usage and generation times
  </Card>
</CardGroup>

## Common Patterns

### Retry with Refinement

```python
async def compose_with_retry(task: str, max_attempts: int = 3):
    for attempt in range(max_attempts):
        try:
            result = await adk.compose(
                task=task,
                context={
                    "attempt": attempt + 1,
                    "previous_errors": locals().get("errors", [])
                }
            )
            return result
        except ProviderError as e:
            errors = locals().get("errors", [])
            errors.append(str(e))
            if attempt == max_attempts - 1:
                raise
            await asyncio.sleep(2 ** attempt)
```

### Progress Tracking

```python
class ProgressTracker:
    def __init__(self):
        self.stages = {
            "context_loading": False,
            "generation": False,
            "validation": False,
            "execution": False
        }
    
    async def track_compose(self, adk, task, mode):
        async for event in adk.compose(task=task, mode=mode, stream=True):
            # Update progress based on events
            if "Loading context" in str(event):
                self.stages["context_loading"] = True
            elif "Generating workflow" in str(event):
                self.stages["generation"] = True
            # ... etc
            
            yield event
```

## Troubleshooting

<AccordionGroup>
  <Accordion title="Empty Results" icon="inbox">
    Ensure your task description is clear:
    ```python
    # Too vague
    task = "backup stuff"
    
    # Better
    task = "Create a workflow to backup all PostgreSQL databases to S3 daily at 2 AM"
    ```
  </Accordion>
  
  <Accordion title="Timeout Issues" icon="clock">
    Increase timeout for complex workflows:
    ```python
    config = ADKConfig(timeout=900)  # 15 minutes
    adk = get_provider("adk", config=config)
    ```
  </Accordion>
  
  <Accordion title="Context Not Used" icon="database">
    Ensure context is properly formatted:
    ```python
    # Wrong
    context = "use kubernetes runner"
    
    # Correct
    context = {
        "preferred_runner": "kubernetes-runner",
        "namespace": "production"
    }
    ```
  </Accordion>
</AccordionGroup>

## Related

<CardGroup cols={2}>
  <Card title="Execute API" icon="play" href="/api-reference/execute">
    Direct workflow execution API
  </Card>
  <Card title="Providers" icon="plug" href="/providers/overview">
    Learn about workflow providers
  </Card>
  <Card title="Streaming" icon="stream" href="/providers/adk/streaming">
    Detailed streaming documentation
  </Card>
  <Card title="Examples" icon="code" href="/tutorials/ai-powered-automation">
    More usage examples
  </Card>
</CardGroup> 